{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"pip install traker","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trak import TRAKer\n\ndef get_trak_matrix(\n    train_dl, val_dl, model, ckpts, train_set_size, val_set_size, **kwargs\n):\n    if kwargs is None or kwargs.get(\"task\") is None:\n        task = \"image_classification\"\n    else:\n        task = kwargs.pop(\"task\")\n\n    traker = TRAKer(model=model, task=task, train_set_size=train_set_size, **kwargs)\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.load_checkpoint(checkpoint, model_id=model_id)\n        for batch in train_dl:\n            batch = [x.cuda() for x in batch]\n            # batch should be a tuple/list of inputs and labels\n            traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n\n    traker.finalize_features()\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.start_scoring_checkpoint(\n            exp_name=\"test\",\n            checkpoint=checkpoint,\n            model_id=model_id,\n            num_targets=val_set_size,\n        )\n    for batch in val_dl:\n        batch = [x.cuda() for x in batch]\n        traker.score(batch=batch, num_samples=batch[0].shape[0])\n\n    scores = traker.finalize_scores(exp_name=\"test\")\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2025-01-15T03:07:32.552963Z","iopub.execute_input":"2025-01-15T03:07:32.553470Z","iopub.status.idle":"2025-01-15T03:07:32.560663Z","shell.execute_reply.started":"2025-01-15T03:07:32.553434Z","shell.execute_reply":"2025-01-15T03:07:32.559561Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.nn import functional as F\n\nclass DDA:\n    def __init__(\n        self,\n        model,\n        checkpoints,\n        train_dataloader,\n        val_dataloader,\n        group_indices,\n        train_set_size=None,\n        val_set_size=None,\n        trak_scores=None,\n        trak_kwargs=None,\n        device=\"cuda\",\n    ) -> None:\n        \n        self.model = model\n        self.checkpoints = checkpoints\n        self.dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n        self.group_indices = group_indices\n        self.device = device\n\n        if trak_scores is not None:\n            self.trak_scores = trak_scores\n        else:\n            try:\n                self.train_set_size = len(train_dataloader.dataset)\n                self.val_set_size = len(val_dataloader.dataset)\n            except AttributeError as e:\n                print(\n                    f\"No dataset attribute found in train_dataloader or val_dataloader. {e}\"\n                )\n                if train_set_size is None or val_set_size is None:\n                    raise ValueError(\n                        \"train_set_size and val_set_size must be specified if \"\n                        \"train_dataloader and val_dataloader do not have a \"\n                        \"dataset attribute.\"\n                    ) from e\n                self.train_set_size = train_set_size\n                self.val_set_size = val_set_size\n\n            # Step 1: compute TRAK scores\n            if trak_kwargs is not None:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                    **trak_kwargs,\n                )\n            else:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                )\n\n            self.trak_scores = trak_scores\n\n    def get_group_losses(self, model, val_dl, group_indices) -> list:\n        losses = []\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in val_dl:\n                outputs = model(inputs.to(self.device))\n                loss = F.cross_entropy(\n                    outputs, labels.to(self.device), reduction=\"none\"\n                )\n                losses.append(loss)\n        losses = torch.cat(losses)\n\n        n_groups = len(set(group_indices))\n        group_losses = [losses[group_indices == i].mean() for i in range(n_groups)]\n        return group_losses\n\n    def compute_group_alignment_scores(self, trak_scores, group_indices, group_losses):\n        n_groups = len(set(group_indices))\n        S = np.array(trak_scores)\n        g = [\n            group_losses[i].cpu().numpy() * S[:, np.array(group_indices) == i].mean(axis=1)\n            for i in range(n_groups)\n        ]\n        g = np.stack(g)\n        group_alignment_scores = g.mean(axis=0)\n        return group_alignment_scores\n\n    def get_debiased_train_indices(\n        self, group_alignment_scores, use_heuristic=True, num_to_discard=None\n    ):\n        if use_heuristic:\n            return [i for i, score in enumerate(group_alignment_scores) if score >= 0]\n\n        if num_to_discard is None:\n            raise ValueError(\"num_to_discard must be specified if not using heuristic.\")\n\n        sorted_indices = sorted(\n            range(len(group_alignment_scores)),\n            key=lambda i: group_alignment_scores[i],\n        )\n        return sorted_indices[num_to_discard:]\n\n    def debias(self, use_heuristic=True, num_to_discard=None):\n        group_losses = self.get_group_losses(\n            model=self.model,\n            val_dl=self.dataloaders[\"val\"],\n            group_indices=self.group_indices,\n        )\n\n        group_alignment_scores = self.compute_group_alignment_scores(\n            self.trak_scores, self.group_indices, group_losses\n        )\n        \n        debiased_train_inds = self.get_debiased_train_indices(\n            group_alignment_scores,\n            use_heuristic=use_heuristic,\n            num_to_discard=num_to_discard,\n        )\n\n        return debiased_train_inds\n","metadata":{"execution":{"iopub.status.busy":"2025-01-15T03:07:33.486123Z","iopub.execute_input":"2025-01-15T03:07:33.486409Z","iopub.status.idle":"2025-01-15T03:07:33.497610Z","shell.execute_reply.started":"2025-01-15T03:07:33.486385Z","shell.execute_reply":"2025-01-15T03:07:33.496858Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"execution":{"iopub.status.busy":"2025-01-15T03:07:34.515566Z","iopub.execute_input":"2025-01-15T03:07:34.515839Z","iopub.status.idle":"2025-01-15T03:07:34.519156Z","shell.execute_reply.started":"2025-01-15T03:07:34.515817Z","shell.execute_reply":"2025-01-15T03:07:34.518542Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# CelebA","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nceleba_images_path = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\npartition_file = \"/kaggle/input/celeba-dataset/list_eval_partition.csv\"\nattributes_file = \"/kaggle/input/celeba-dataset/list_attr_celeba.csv\"\n\npartitions = pd.read_csv(partition_file)\nattributes = pd.read_csv(attributes_file)\n\ndef get_dataloader(\n        batch_size=128, num_workers=4, split=\"train\", shuffle=False, augment=True\n    ):\n    if augment:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.RandomHorizontalFlip(),\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n    else:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n\n    attributes.iloc[:, 1:] = attributes.iloc[:, 1:].map(lambda x: 1 if x == 1 else 0)\n\n    total_indices = len(attributes)\n    reduced_indices = np.random.choice(attributes.index, size=total_indices // 5, replace=False)\n\n    blond_indices = attributes[attributes[\"Blond_Hair\"] == 1].index.intersection(reduced_indices)\n    non_blond_indices = attributes[attributes[\"Blond_Hair\"] == 0].index.intersection(reduced_indices)\n\n    num_non_blond = len(non_blond_indices)\n    num_blond = min(len(blond_indices), num_non_blond * 4)\n    selected_blond_indices = np.random.choice(blond_indices, num_blond, replace=False)\n    selected_indices = np.concatenate([selected_blond_indices, non_blond_indices])\n\n    dataset_split = \"train\" if split == \"train\" else \"valid\"\n    if dataset_split == \"train\":\n        selected_indices = partitions[\n            (partitions[\"partition\"] == 0) & partitions.index.isin(selected_indices)\n        ].index\n    else:\n        selected_indices = partitions[\n            (partitions[\"partition\"] == 1) & partitions.index.isin(selected_indices)\n        ].index\n\n    class CelebADataset(torch.utils.data.Dataset):\n        def __init__(self, indices, img_dir, attributes, transform=None):\n            self.indices = indices\n            self.img_dir = img_dir\n            self.attributes = attributes\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.indices)\n\n        def __getitem__(self, idx):\n            img_index = self.indices[idx]\n            img_name = self.attributes.iloc[img_index, 0]\n            img_path = os.path.join(self.img_dir, img_name)\n\n            image = Image.open(img_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n\n            label = torch.tensor(self.attributes.iloc[img_index][\"Blond_Hair\"], dtype=torch.long)\n            return image, label\n\n    dataset = CelebADataset(\n        indices=selected_indices,\n        img_dir=celeba_images_path,\n        attributes=attributes,\n        transform=transforms_pipeline\n    )\n\n    loader = DataLoader(\n        dataset=dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers\n    )\n\n    return loader, dataset\n\nfrom torchvision.models import resnet18, ResNet18_Weights\nmodel_before_mitigating = resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel_before_mitigating.fc = nn.Linear(model_before_mitigating.fc.in_features, 2)\nmodel_before_mitigating = model_before_mitigating.cuda()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_before_mitigating.parameters(), lr=0.001)\n\ntrain_loader, train_dataset = get_dataloader(batch_size=32, split=\"train\", shuffle=True)\nval_loader, val_dataset = get_dataloader(batch_size=32, split=\"val\", shuffle=False, augment=False)\n\nnum_epochs = 1\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    model_before_mitigating.train()\n    epoch_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=\"Training\"):\n        images = images.cuda()\n        labels = labels.cuda()\n\n        outputs = model_before_mitigating(images)\n        loss = criterion(outputs, labels)\n        epoch_loss += loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Training Loss: {avg_loss:.4f}\")\n\n    model_before_mitigating.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n            images = images.cuda()\n            labels = labels.cuda()\n            outputs = model_before_mitigating(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n\nprint(\"Training and evaluation completed.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport numpy as np\n\ndef evaluate_worst_group_accuracy(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval()\n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating WGA\")):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])  \n                group_labels[group].append(labels.cpu().numpy()[i])  \n\n    group_accuracies = {}\n    for group in group_preds.keys():\n        if len(group_preds[group]) == 0 or len(group_labels[group]) == 0:\n            group_accuracies[group] = 0.0\n            continue\n\n        preds = np.array(group_preds[group])\n        truths = np.array(group_labels[group])\n        group_accuracies[group] = accuracy_score(truths, preds)\n\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n\n    worst_group_accuracy = min(group_accuracies.values())\n    return worst_group_accuracy, group_accuracies","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:16:43.758090Z","iopub.status.busy":"2025-01-09T21:16:43.757407Z","iopub.status.idle":"2025-01-09T21:16:43.766032Z","shell.execute_reply":"2025-01-09T21:16:43.765232Z","shell.execute_reply.started":"2025-01-09T21:16:43.758060Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"attributes = pd.read_csv(attributes_file)\nattributes.iloc[:, 1:] = attributes.iloc[:, 1:].map(lambda x: 1 if x == 1 else 0)\n\ndef define_subgroups(row):\n    if row[\"Young\"] == 1 and row[\"Male\"] == 1:\n        return \"young-male\"\n    elif row[\"Young\"] == 1 and row[\"Male\"] == 0:\n        return \"young-female\"\n    elif row[\"Young\"] == 0 and row[\"Male\"] == 1:\n        return \"old-male\"\n    elif row[\"Young\"] == 0 and row[\"Male\"] == 0:\n        return \"old-female\"\n\nattributes[\"subgroup\"] = attributes.apply(define_subgroups, axis=1)\n\nsubgroup_mapping = {name: i for i, name in enumerate(sorted(attributes[\"subgroup\"].unique()))}\nattributes[\"group_index\"] = attributes[\"subgroup\"].map(subgroup_mapping)\n\nval_indices = list(val_loader.dataset.indices)\ngroup_labels = attributes.loc[attributes.index.intersection(val_indices), \"group_index\"].values\ngroup_inds = attributes['subgroup'].map(subgroup_mapping).values # I should check the group indices later to make sure it works well or not.\n\n\nprint(\"Subgroup Distribution in Validation Set:\")\nprint(attributes.loc[val_indices, \"subgroup\"].value_counts())\n# print(f\"Sample Group Indices: {group_inds[:10]}\")\n\nprint(\"Unique Subgroups in Validation Set:\")\nprint(attributes.loc[val_indices, \"subgroup\"].unique())","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:16:45.771992Z","iopub.status.busy":"2025-01-09T21:16:45.771684Z","iopub.status.idle":"2025-01-09T21:16:50.988764Z","shell.execute_reply":"2025-01-09T21:16:50.987695Z","shell.execute_reply.started":"2025-01-09T21:16:45.771970Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Subgroup Distribution in Validation Set:\n","subgroup\n","young-female    1970\n","young-male      1077\n","old-male         632\n","old-female       359\n","Name: count, dtype: int64\n","Unique Subgroups in Validation Set:\n","['young-female' 'old-male' 'young-male' 'old-female']\n"]}],"execution_count":8},{"cell_type":"markdown","source":"**Calculating Fairness Metrics for Young and Old Groups**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\n\ndef evaluate_group_accuracies(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_preds = {g: [] for g in set(group_labels)}\n    group_truths = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Group Accuracies\")):\n            images = images.to(device)\n            labels = labels.to(device)  \n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_preds[group].append(preds[j])\n                group_truths[group].append(labels.cpu().numpy()[j])\n\n    group_accuracies = {}\n    for group in group_preds:\n        if len(group_preds[group]) == 0:\n            group_accuracies[group] = 0.0\n        else:\n            preds = np.array(group_preds[group])\n            truths = np.array(group_truths[group])\n            group_accuracies[group] = accuracy_score(truths, preds)\n\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n    \n    return group_accuracies\n\ndef evaluate_demographic_parity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_pprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, _) in enumerate(tqdm(val_loader, desc=\"Evaluating Demographic Parity\")):\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(preds)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_pprs[group].append(preds[j])\n\n    ppr_disparities = {}\n    for group in group_pprs:\n        group_positive_rate = np.mean(group_pprs[group])\n        ppr_disparities[group] = group_positive_rate\n\n    for group, ppr in ppr_disparities.items():\n        print(f\"Group {group} PPR: {ppr:.4f}\")\n    \n    return ppr_disparities\n\ndef evaluate_equal_opportunity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equal Opportunity\")):\n            images = images.to(device)\n            labels = labels.to(device)  \n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                actual_positive = labels[j].cpu().numpy() == 1\n                group_tprs[group].append(tp / (actual_positive + 1e-8)) \n\n    tpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n\n    for group, tpr in tpr_disparities.items():\n        print(f\"Group {group} TPR: {tpr:.4f}\")\n    \n    return tpr_disparities\n\ndef evaluate_equalized_odds(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n    group_fprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equalized Odds\")):\n            images = images.to(device)\n            labels = labels.to(device) \n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                fp = (preds[j] == 1 and labels[j].cpu().numpy() == 0)\n                actual_positive = labels[j].cpu().numpy() == 1\n                actual_negative = labels[j].cpu().numpy() == 0\n\n                group_tprs[group].append(tp / (actual_positive + 1e-8))\n                group_fprs[group].append(fp / (actual_negative + 1e-8))\n\n    tpr_disparities = {}\n    fpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n        fpr_disparities[group] = np.mean(group_fprs[group])\n\n    for group in group_tprs:\n        print(f\"Group {group} TPR: {tpr_disparities[group]:.4f}, FPR: {fpr_disparities[group]:.4f}\")\n    \n    return tpr_disparities, fpr_disparities","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:17:01.303262Z","iopub.status.busy":"2025-01-09T21:17:01.302945Z","iopub.status.idle":"2025-01-09T21:17:01.319567Z","shell.execute_reply":"2025-01-09T21:17:01.318611Z","shell.execute_reply.started":"2025-01-09T21:17:01.303228Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"wga, group_accuracies = evaluate_worst_group_accuracy(model_before_mitigating, val_loader, group_labels)\ndp_rates = evaluate_demographic_parity(model_before_mitigating, val_loader, group_labels)\neo_tprs = evaluate_equal_opportunity(model_before_mitigating, val_loader, group_labels)\ntpr_disparities, fpr_disparities = evaluate_equalized_odds(model_before_mitigating, val_loader, group_labels)","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:17:02.514396Z","iopub.status.busy":"2025-01-09T21:17:02.514069Z","iopub.status.idle":"2025-01-09T21:17:18.101801Z","shell.execute_reply":"2025-01-09T21:17:18.100818Z","shell.execute_reply.started":"2025-01-09T21:17:02.514366Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 127/127 [00:04<00:00, 30.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0 Accuracy: 0.2841\n","Group 1 Accuracy: 0.7168\n","Group 2 Accuracy: 0.9873\n","Group 3 Accuracy: 0.8784\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating Demographic Parity: 100%|██████████| 127/127 [00:03<00:00, 33.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0 PPR: 0.7159\n","Group 1 PPR: 0.2832\n","Group 2 PPR: 0.9873\n","Group 3 PPR: 0.8784\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating Equal Opportunity: 100%|██████████| 127/127 [00:03<00:00, 33.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0 TPR: 0.0000\n","Group 1 TPR: 0.0000\n","Group 2 TPR: 0.9873\n","Group 3 TPR: 0.8784\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating Equalized Odds: 100%|██████████| 127/127 [00:03<00:00, 33.49it/s]"]},{"name":"stdout","output_type":"stream","text":["Group 0 TPR: 0.0000, FPR: 0.7159\n","Group 1 TPR: 0.0000, FPR: 0.2832\n","Group 2 TPR: 0.9873, FPR: 0.0000\n","Group 3 TPR: 0.8784, FPR: 0.0000\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":10},{"cell_type":"markdown","source":"# Debiasing with D3M","metadata":{}},{"cell_type":"code","source":"print('YOYO')\nckpts = [model_before_mitigating.state_dict()]\n\ndda = DDA(\n    model=model_before_mitigating,\n    checkpoints=[model_before_mitigating.state_dict()],\n    train_dataloader=train_loader,\n    val_dataloader=val_loader,\n    group_indices=group_inds\n)","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:17:53.857843Z","iopub.status.busy":"2025-01-09T21:17:53.857481Z","iopub.status.idle":"2025-01-09T21:45:39.398323Z","shell.execute_reply":"2025-01-09T21:45:39.397496Z","shell.execute_reply.started":"2025-01-09T21:17:53.857813Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["YOYO\n"]},{"name":"stderr","output_type":"stream","text":["Finalizing features for all model IDs..: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n","Finalizing scores for all model IDs..: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n"]}],"execution_count":12},{"cell_type":"code","source":"# debiased_inds = dda.debias(use_heuristic=False, num_to_discard=100)\ndebiased_inds = dda.debias(use_heuristic=True)\nlen(debiased_inds)","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:49:26.056442Z","iopub.status.busy":"2025-01-09T21:49:26.056128Z","iopub.status.idle":"2025-01-09T21:49:31.792483Z","shell.execute_reply":"2025-01-09T21:49:31.791289Z","shell.execute_reply.started":"2025-01-09T21:49:26.056420Z"},"trusted":true},"outputs":[{"data":{"text/plain":["13629"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"execution_count":14},{"cell_type":"code","source":"import copy\n\ndeep_copy_model = copy.deepcopy(model_before_mitigating)","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:49:35.289727Z","iopub.status.busy":"2025-01-09T21:49:35.289356Z","iopub.status.idle":"2025-01-09T21:49:35.309843Z","shell.execute_reply":"2025-01-09T21:49:35.309174Z","shell.execute_reply.started":"2025-01-09T21:49:35.289697Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Machine Unlearning","metadata":{}},{"cell_type":"code","source":"all_train_indices = np.arange(len(train_loader.dataset))\nharmful_indices = np.setdiff1d(all_train_indices, debiased_inds)","metadata":{"execution":{"iopub.execute_input":"2025-01-09T21:49:42.326562Z","iopub.status.busy":"2025-01-09T21:49:42.326240Z","iopub.status.idle":"2025-01-09T21:49:42.330595Z","shell.execute_reply":"2025-01-09T21:49:42.329613Z","shell.execute_reply.started":"2025-01-09T21:49:42.326536Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def remove_influence(model, dataloader, harmful_indices, factor, device=\"cuda\"):\n    model.eval()\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    for inputs, labels in harmful_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(model.parameters(), grads):\n                param -= grad * factor\n\n    return model\n\nresults ={'factor':[], 'model':[], 'min':[], 'max':[], 'gap':[]}\nfactors = np.linspace(0.0001, 0.001, 2)\n\nfor factor in factors:\n    newdeepmodel = copy.deepcopy(deep_copy_model)\n    m = remove_influence(newdeepmodel, train_loader, harmful_indices, factor, device=\"cuda\")\n    wga, group_accs = evaluate_worst_group_accuracy(m, val_loader, group_inds, device=\"cuda\")\n    current_gap = (max(group_accs.values()) - wga)\n    results['model'].append(m)\n    results['min'].append(wga)\n    results['max'].append(max(group_accs.values()))\n    results['gap'].append(current_gap)\n    results['factor'].append(factor)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(results).sort_values('factor')\ndf","metadata":{"execution":{"iopub.execute_input":"2025-01-09T17:56:45.547620Z","iopub.status.busy":"2025-01-09T17:56:45.547251Z","iopub.status.idle":"2025-01-09T17:56:45.569290Z","shell.execute_reply":"2025-01-09T17:56:45.568481Z","shell.execute_reply.started":"2025-01-09T17:56:45.547586Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>factor</th>\n","      <th>model</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>gap</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00001</td>\n","      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n","      <td>0.327957</td>\n","      <td>0.972888</td>\n","      <td>0.644931</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.00010</td>\n","      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n","      <td>0.419355</td>\n","      <td>0.972888</td>\n","      <td>0.553534</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    factor                                              model       min  \\\n","0  0.00001  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.327957   \n","1  0.00010  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.419355   \n","\n","        max       gap  \n","0  0.972888  0.644931  \n","1  0.972888  0.553534  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"execution_count":36},{"cell_type":"markdown","source":"Now, it's time to investigate what are the best approaches to machine unlearning and how can we formulate that.","metadata":{}},{"cell_type":"markdown","source":"What are the other approaches to machine unlearning?","metadata":{}},{"cell_type":"markdown","source":"# Fair Pruning","metadata":{}},{"cell_type":"code","source":"import torch\nimport copy\n\ndef fair_pruning(model, dataloader, harmful_indices, threshold=0.01, device=\"cuda\"):\n    model.eval()\n    pruned_model = copy.deepcopy(model)\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    parameter_gradients = []\n    for inputs, labels in tqdm(harmful_loader, desc=\"Calculating Gradients\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = pruned_model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, pruned_model.parameters(), retain_graph=True)\n        parameter_gradients.append([grad.clone() for grad in grads])\n\n    with torch.no_grad():\n        for param, grads in zip(pruned_model.parameters(), zip(*parameter_gradients)):\n            mean_grad = torch.mean(torch.stack(grads), dim=0)\n            param[torch.abs(mean_grad) < threshold] = 0.0\n\n    return pruned_model\n\npruned_model = fair_pruning(model_before_mitigating, train_loader, harmful_indices, threshold=0.01)\n\nwga, group_accs = evaluate_worst_group_accuracy(pruned_model, val_loader, group_inds, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Differentially Private Influence Functions for Unlearning","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport copy\n\ndef dp_influence_unlearning(model, dataloader, harmful_indices, epsilon=1.0, delta=1e-5, device=\"cuda\"):\n    model.eval()\n    updated_model = copy.deepcopy(model)\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    sensitivity = 1.0 / len(harmful_loader)\n    noise_scale = sensitivity * np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n\n    for inputs, labels in tqdm(harmful_loader, desc=\"Applying DP Influence Unlearning\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = updated_model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, updated_model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(updated_model.parameters(), grads):\n                noise = torch.normal(mean=0, std=noise_scale, size=grad.shape, device=device)\n                param -= (grad + noise)\n\n    return updated_model\n\ndp_model = dp_influence_unlearning(model_before_mitigating, train_loader, harmful_indices, epsilon=1.0, delta=1e-5)\nwga, group_accs = evaluate_worst_group_accuracy(dp_model, val_loader, group_inds, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
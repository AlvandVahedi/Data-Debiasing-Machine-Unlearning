{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":10372207,"sourceType":"datasetVersion","datasetId":6424878},{"sourceId":167875528,"sourceType":"kernelVersion"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install traker","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trak import TRAKer\n\ndef get_trak_matrix(\n    train_dl, val_dl, model, ckpts, train_set_size, val_set_size, **kwargs\n):\n    if kwargs is None or kwargs.get(\"task\") is None:\n        task = \"image_classification\"\n    else:\n        task = kwargs.pop(\"task\")\n\n    traker = TRAKer(model=model, task=task, train_set_size=train_set_size, **kwargs)\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.load_checkpoint(checkpoint, model_id=model_id)\n        for batch in train_dl:\n            batch = [x.cuda() for x in batch]\n            # batch should be a tuple/list of inputs and labels\n            traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n\n    traker.finalize_features()\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.start_scoring_checkpoint(\n            exp_name=\"test\",\n            checkpoint=checkpoint,\n            model_id=model_id,\n            num_targets=val_set_size,\n        )\n    for batch in val_dl:\n        batch = [x.cuda() for x in batch]\n        traker.score(batch=batch, num_samples=batch[0].shape[0])\n\n    scores = traker.finalize_scores(exp_name=\"test\")\n    return scores\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:30:14.126027Z","iopub.execute_input":"2025-01-04T20:30:14.126347Z","iopub.status.idle":"2025-01-04T20:30:17.091585Z","shell.execute_reply.started":"2025-01-04T20:30:14.126319Z","shell.execute_reply":"2025-01-04T20:30:17.090704Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.nn import functional as F\n\nclass DDA:\n    \"\"\"\n    Debiasing through Data Attribution\n    \"\"\"\n\n    def __init__(\n        self,\n        model,\n        checkpoints,\n        train_dataloader,\n        val_dataloader,\n        group_indices,\n        train_set_size=None,\n        val_set_size=None,\n        trak_scores=None,\n        trak_kwargs=None,\n        device=\"cuda\",\n    ) -> None:\n        \"\"\"\n        Args:\n            model:\n                The model to be debiased.\n            checkpoints:\n                A list of model checkpoints (state dictionaries) for debiasing\n                (used to compute TRAK scores).\n            train_dataloader:\n                DataLoader for the training dataset.\n            val_dataloader:\n                DataLoader for the validation dataset.\n            group_indices:\n                A list indicating the group each sample in the validation\n                dataset belongs to.\n            train_set_size (optional):\n                The size of the training dataset. Required if the dataloader\n                does not have a dataset attribute.\n            val_set_size (optional):\n                The size of the validation dataset. Required if the dataloader\n                does not have a dataset attribute.\n            trak_scores (optional):\n                Precomputed TRAK scores. If not provided, they will be computed\n                from scratch.\n            trak_kwargs (optional):\n                Additional keyword arguments to be passed to\n                `attrib.get_trak_matrix`.\n            device (optional):\n                pytorch device\n        \"\"\"\n        self.model = model\n        self.checkpoints = checkpoints\n        self.dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n        self.group_indices = group_indices\n        self.device = device\n\n        if trak_scores is not None:\n            self.trak_scores = trak_scores\n        else:\n            try:\n                self.train_set_size = len(train_dataloader.dataset)\n                self.val_set_size = len(val_dataloader.dataset)\n            except AttributeError as e:\n                print(\n                    f\"No dataset attribute found in train_dataloader or val_dataloader. {e}\"\n                )\n                if train_set_size is None or val_set_size is None:\n                    raise ValueError(\n                        \"train_set_size and val_set_size must be specified if \"\n                        \"train_dataloader and val_dataloader do not have a \"\n                        \"dataset attribute.\"\n                    ) from e\n                self.train_set_size = train_set_size\n                self.val_set_size = val_set_size\n\n            # Step 1: compute TRAK scores\n            if trak_kwargs is not None:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                    **trak_kwargs,\n                )\n            else:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                )\n\n            self.trak_scores = trak_scores\n\n    def get_group_losses(self, model, val_dl, group_indices) -> list:\n        \"\"\"Returns a list of losses for each group in the validation set.\"\"\"\n        losses = []\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in val_dl:\n                outputs = model(inputs.to(self.device))\n                loss = F.cross_entropy(\n                    outputs, labels.to(self.device), reduction=\"none\"\n                )\n                losses.append(loss)\n        losses = torch.cat(losses)\n\n        n_groups = len(set(group_indices))\n        group_losses = [losses[group_indices == i].mean() for i in range(n_groups)]\n        return group_losses\n\n    def compute_group_alignment_scores(self, trak_scores, group_indices, group_losses):\n        \"\"\"\n        Computes group alignment scores (check Section 3.2 in our paper for\n        details).\n\n        Args:\n            trak_scores:\n                result of get_trak_matrix\n            group_indices:\n                a list of the form [group_index(x) for x in train_dataset]\n\n        Returns:\n            a list of group alignment scores for each training example\n        \"\"\"\n        n_groups = len(set(group_indices))\n        S = np.array(trak_scores)\n        g = [\n            group_losses[i].cpu().numpy() * S[:, np.array(group_indices) == i].mean(axis=1)\n            for i in range(n_groups)\n        ]\n        g = np.stack(g)\n        group_alignment_scores = g.mean(axis=0)\n        return group_alignment_scores\n\n    def get_debiased_train_indices(\n        self, group_alignment_scores, use_heuristic=True, num_to_discard=None\n    ):\n        \"\"\"\n        If use_heuristic is True, training examples with negative score will be discarded,\n        and the parameter num_to_discard will be ignored\n        Otherwise, the num_to_discard training examples with lowest scores will be discarded.\n        \"\"\"\n        if use_heuristic:\n            return [i for i, score in enumerate(group_alignment_scores) if score >= 0]\n\n        if num_to_discard is None:\n            raise ValueError(\"num_to_discard must be specified if not using heuristic.\")\n\n        sorted_indices = sorted(\n            range(len(group_alignment_scores)),\n            key=lambda i: group_alignment_scores[i],\n        )\n        return sorted_indices[num_to_discard:]\n\n    def debias(self, use_heuristic=True, num_to_discard=None):\n        \"\"\"\n        Debiases the training process by constructing a new training set that\n        excludes examples which harm worst-group accuracy.\n\n        Args:\n            use_heuristic:\n                If True, examples with negative group alignment scores are\n                discarded.  If False, the `num_to_discard` examples with the\n                lowest scores are discarded.\n            num_to_discard:\n                The number of training examples to discard based on their group\n                alignment scores.  This parameter is ignored if `use_heuristic`\n                is True.\n\n        Returns:\n            debiased_train_inds (list):\n                A list of indices for the training examples that should be\n                included in the debiased training set.\n        \"\"\"\n\n        # Step 2 (Step 1 is to compute TRAK scores):\n        # compute group alignment scores\n        group_losses = self.get_group_losses(\n            model=self.model,\n            val_dl=self.dataloaders[\"val\"],\n            group_indices=self.group_indices,\n        )\n\n        group_alignment_scores = self.compute_group_alignment_scores(\n            self.trak_scores, self.group_indices, group_losses\n        )\n\n        # Step 3:\n        # construct new training set\n        debiased_train_inds = self.get_debiased_train_indices(\n            group_alignment_scores,\n            use_heuristic=use_heuristic,\n            num_to_discard=num_to_discard,\n        )\n\n        return debiased_train_inds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:30:21.047697Z","iopub.execute_input":"2025-01-04T20:30:21.048127Z","iopub.status.idle":"2025-01-04T20:30:21.061004Z","shell.execute_reply.started":"2025-01-04T20:30:21.048100Z","shell.execute_reply":"2025-01-04T20:30:21.060211Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:30:25.541936Z","iopub.execute_input":"2025-01-04T20:30:25.542237Z","iopub.status.idle":"2025-01-04T20:30:25.545684Z","shell.execute_reply.started":"2025-01-04T20:30:25.542213Z","shell.execute_reply":"2025-01-04T20:30:25.544852Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# CelebA","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom PIL import Image\nimport pandas as pd\n\n# Path to CelebA images and metadata\nceleba_images_path = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\npartition_file = \"/kaggle/input/celeba-dataset/list_eval_partition.csv\"\nattributes_file = \"/kaggle/input/celeba-dataset/list_attr_celeba.csv\"\n\n# Function to get DataLoader for CelebA\ndef get_dataloader(\n        batch_size=128, num_workers=4, split=\"train\", shuffle=False, augment=True\n    ):\n    \"\"\"\n    Get DataLoader for the CelebA dataset.\n    \"\"\"\n    # Define transformations\n    if augment:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.RandomHorizontalFlip(),\n                transforms.CenterCrop(178),  # Crop central face region\n                transforms.Resize(128),  # Resize to smaller dimensions\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),  # Normalize to [-1, 1]\n            ]\n        )\n    else:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n\n    # Determine dataset split\n    dataset_split = \"train\" if split == \"train\" else \"valid\"\n\n    # Load partition and attributes\n    partitions = pd.read_csv(partition_file)\n    attributes = pd.read_csv(attributes_file)\n\n    # Ensure attributes are binary\n    attributes.iloc[:, 1:] = attributes.iloc[:, 1:].applymap(lambda x: 1 if x == 1 else 0)\n\n    # Select indices based on split\n    if dataset_split == \"train\":\n        selected_indices = partitions[partitions['partition'] == 0].index\n    else:\n        selected_indices = partitions[partitions['partition'] == 1].index\n\n    # Custom Dataset class for CelebA\n    class CelebADataset(torch.utils.data.Dataset):\n        def __init__(self, indices, img_dir, attributes, transform=None):\n            self.indices = indices\n            self.img_dir = img_dir\n            self.attributes = attributes\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.indices)\n\n        def __getitem__(self, idx):\n            img_index = self.indices[idx]\n            img_name = self.attributes.iloc[img_index, 0]  # Image file name\n            img_path = os.path.join(self.img_dir, img_name)\n\n            # Load and preprocess the image\n            image = Image.open(img_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n\n            # Get class label (convert to long tensor)\n            label = torch.tensor(self.attributes.iloc[img_index, 1:].values.astype('float32'))\n            label = label.argmax().long()\n            return image, label\n\n    # Create Dataset and DataLoader\n    dataset = CelebADataset(\n        indices=selected_indices,\n        img_dir=celeba_images_path,\n        attributes=attributes,\n        transform=transforms_pipeline\n    )\n\n    loader = DataLoader(\n        dataset=dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers\n    )\n\n    return loader, dataset\n\n# Load pre-trained model\nfrom torchvision.models import resnet18, ResNet18_Weights\nmodel_before_mitigating = resnet18(weights=ResNet18_Weights.DEFAULT).cuda()\nmodel_before_mitigating.eval()  # Set model to evaluation mode\n\n# Define loss function and optimizer\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model_before_mitigating.parameters(), lr=0.001, momentum=0.9)\n\n# Get DataLoaders\ntrain_loader, train_dataset = get_dataloader(batch_size=32, split=\"train\")\nval_loader, val_dataset = get_dataloader(batch_size=32, split=\"val\", shuffle=False, augment=False)\n\n# Training Loop\nnum_epochs = 4  # Adjust as needed\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    model_before_mitigating.train()  # Set model to training mode\n    epoch_loss = 0.0\n    for i, (images, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n        images = images.cuda()\n        labels = labels.cuda()\n\n        # Forward pass\n        outputs = model_before_mitigating(images)\n        loss = criterion(outputs, labels)\n        epoch_loss += loss.item()\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Training Loss: {avg_loss:.4f}\")\n\n    # Evaluation\n    model_before_mitigating.eval()  # Set model to evaluation mode\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n            images = images.cuda()\n            labels = labels.cuda()\n            outputs = model_before_mitigating(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n\n# Final Output\nprint(\"Training and evaluation completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:36:23.419972Z","iopub.execute_input":"2025-01-03T22:36:23.420256Z","iopub.status.idle":"2025-01-03T22:54:00.713926Z","shell.execute_reply.started":"2025-01-03T22:36:23.420234Z","shell.execute_reply":"2025-01-03T22:54:00.712829Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 84.3MB/s]\n<ipython-input-6-1207a786f729>:51: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  attributes.iloc[:, 1:] = attributes.iloc[:, 1:].applymap(lambda x: 1 if x == 1 else 0)\n<ipython-input-6-1207a786f729>:51: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  attributes.iloc[:, 1:] = attributes.iloc[:, 1:].applymap(lambda x: 1 if x == 1 else 0)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 5087/5087 [05:44<00:00, 14.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 1.3825\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 621/621 [00:37<00:00, 16.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 57.65%\n\nEpoch 2/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 5087/5087 [03:21<00:00, 25.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 1.1890\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 621/621 [00:20<00:00, 30.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 58.43%\n\nEpoch 3/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 5087/5087 [03:21<00:00, 25.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 1.1290\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 621/621 [00:20<00:00, 30.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 58.75%\n\nEpoch 4/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 5087/5087 [03:21<00:00, 25.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 1.0797\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 621/621 [00:20<00:00, 30.53it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 58.57%\nTraining and evaluation completed.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CelebA attributes file\nattributes_file = \"/kaggle/input/celeba-dataset/list_attr_celeba.csv\"\nattributes = pd.read_csv(attributes_file)\n\nattributes['Young'] = attributes['Young'].apply(lambda x: 1 if x == 1 else 0)\nattributes['Male'] = attributes['Male'].apply(lambda x: 1 if x == 1 else 0)\n\ndef define_subgroups(row):\n    if row['Young'] == 1 and row['Male'] == 1:\n        return 'young-male'\n    elif row['Young'] == 1 and row['Male'] == 0:\n        return 'young-female'\n    elif row['Young'] == 0 and row['Male'] == 1:\n        return 'old-male'\n    elif row['Young'] == 0 and row['Male'] == 0:\n        return 'old-female'\n\nattributes['subgroup'] = attributes.apply(define_subgroups, axis=1)\n\nsubgroup_mapping = {name: i for i, name in enumerate(attributes['subgroup'].unique())}\nattributes['group_index'] = attributes['subgroup'].map(subgroup_mapping)\n\nprint(\"Subgroup Distribution:\")\nprint(attributes['subgroup'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:54:03.685872Z","iopub.execute_input":"2025-01-03T22:54:03.686175Z","iopub.status.idle":"2025-01-03T22:54:06.687382Z","shell.execute_reply.started":"2025-01-03T22:54:03.686151Z","shell.execute_reply":"2025-01-03T22:54:06.686648Z"}},"outputs":[{"name":"stdout","text":"Subgroup Distribution:\nsubgroup\nyoung-female    103287\nyoung-male       53447\nold-male         30987\nold-female       14878\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"group_labels = attributes.loc[val_dataset.indices, 'group_index'].values\n# group_inds = group_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:54:16.162564Z","iopub.execute_input":"2025-01-03T22:54:16.162863Z","iopub.status.idle":"2025-01-03T22:54:16.168006Z","shell.execute_reply.started":"2025-01-03T22:54:16.162841Z","shell.execute_reply":"2025-01-03T22:54:16.167282Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport numpy as np\n\ndef evaluate_worst_group_accuracy(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval()  # Set model to evaluation mode\n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating WGA\")):\n            inputs = inputs.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` since labels are not one-hot encoded\n\n            # Predict using the model\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Assign predictions and labels to the respective group\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])  # Add single prediction\n                group_labels[group].append(labels.cpu().numpy()[i])  # Add single label\n\n    group_accuracies = {}\n    for group in group_preds.keys():\n        if len(group_preds[group]) == 0 or len(group_labels[group]) == 0:\n            # Skip groups with no samples\n            group_accuracies[group] = 0.0\n            continue\n\n        # Convert lists to arrays\n        preds = np.array(group_preds[group])\n        truths = np.array(group_labels[group])\n        group_accuracies[group] = accuracy_score(truths, preds)\n\n    # Print all group accuracies\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n\n    # Find the worst group accuracy\n    worst_group_accuracy = min(group_accuracies.values())\n    return worst_group_accuracy, group_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:39:21.459531Z","iopub.execute_input":"2025-01-04T20:39:21.459822Z","iopub.status.idle":"2025-01-04T20:39:21.467294Z","shell.execute_reply.started":"2025-01-04T20:39:21.459800Z","shell.execute_reply":"2025-01-04T20:39:21.466325Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"**Calculating Fairness Metrics for Young and Old Groups**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\n\n# Function to evaluate Group Accuracies\ndef evaluate_group_accuracies(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_preds = {g: [] for g in set(group_labels)}\n    group_truths = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Group Accuracies\")):\n            images = images.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` here\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Assign predictions and truths to respective groups\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_preds[group].append(preds[j])\n                group_truths[group].append(labels.cpu().numpy()[j])\n\n    group_accuracies = {}\n    for group in group_preds:\n        if len(group_preds[group]) == 0:\n            group_accuracies[group] = 0.0\n        else:\n            preds = np.array(group_preds[group])\n            truths = np.array(group_truths[group])\n            group_accuracies[group] = accuracy_score(truths, preds)\n\n    # Print group accuracies\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n    \n    return group_accuracies\n\n# Function to evaluate Demographic Parity (DP)\ndef evaluate_demographic_parity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_pprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, _) in enumerate(tqdm(val_loader, desc=\"Evaluating Demographic Parity\")):\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(preds)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_pprs[group].append(preds[j])\n\n    ppr_disparities = {}\n    for group in group_pprs:\n        group_positive_rate = np.mean(group_pprs[group])\n        ppr_disparities[group] = group_positive_rate\n\n    # Print group PPRs\n    for group, ppr in ppr_disparities.items():\n        print(f\"Group {group} PPR: {ppr:.4f}\")\n    \n    return ppr_disparities\n\n# Function to evaluate Equal Opportunity (EO)\ndef evaluate_equal_opportunity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equal Opportunity\")):\n            images = images.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` here\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                actual_positive = labels[j].cpu().numpy() == 1\n                group_tprs[group].append(tp / (actual_positive + 1e-8))  # Avoid division by zero\n\n    tpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n\n    # Print group TPRs\n    for group, tpr in tpr_disparities.items():\n        print(f\"Group {group} TPR: {tpr:.4f}\")\n    \n    return tpr_disparities\n\n# Function to evaluate Equalized Odds (EOd)\ndef evaluate_equalized_odds(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n    group_fprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equalized Odds\")):\n            images = images.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` here\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                fp = (preds[j] == 1 and labels[j].cpu().numpy() == 0)\n                actual_positive = labels[j].cpu().numpy() == 1\n                actual_negative = labels[j].cpu().numpy() == 0\n\n                group_tprs[group].append(tp / (actual_positive + 1e-8))  # Avoid division by zero\n                group_fprs[group].append(fp / (actual_negative + 1e-8))  # Avoid division by zero\n\n    tpr_disparities = {}\n    fpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n        fpr_disparities[group] = np.mean(group_fprs[group])\n\n    # Print group TPRs and FPRs\n    for group in group_tprs:\n        print(f\"Group {group} TPR: {tpr_disparities[group]:.4f}, FPR: {fpr_disparities[group]:.4f}\")\n    \n    return tpr_disparities, fpr_disparities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:54:24.096409Z","iopub.execute_input":"2025-01-03T22:54:24.097018Z","iopub.status.idle":"2025-01-03T22:54:24.113439Z","shell.execute_reply.started":"2025-01-03T22:54:24.096991Z","shell.execute_reply":"2025-01-03T22:54:24.112539Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"wga, group_accuracies = evaluate_worst_group_accuracy(model_before_mitigating, val_loader, group_labels)\ndp_rates = evaluate_demographic_parity(model_before_mitigating, val_loader, group_labels)\neo_tprs = evaluate_equal_opportunity(model_before_mitigating, val_loader, group_labels)\ntpr_disparities, fpr_disparities = evaluate_equalized_odds(model_before_mitigating, val_loader, group_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:54:31.197123Z","iopub.execute_input":"2025-01-03T22:54:31.197444Z","iopub.status.idle":"2025-01-03T22:55:47.039303Z","shell.execute_reply.started":"2025-01-03T22:54:31.197416Z","shell.execute_reply":"2025-01-03T22:55:47.038224Z"}},"outputs":[{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 621/621 [00:20<00:00, 30.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.6536\nGroup 1 Accuracy: 0.5402\nGroup 2 Accuracy: 0.4719\nGroup 3 Accuracy: 0.5593\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Demographic Parity: 100%|██████████| 621/621 [00:18<00:00, 33.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 PPR: 2.0323\nGroup 1 PPR: 2.7719\nGroup 2 PPR: 4.5824\nGroup 3 PPR: 2.8930\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Equal Opportunity: 100%|██████████| 621/621 [00:18<00:00, 34.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 TPR: 0.3203\nGroup 1 TPR: 0.0146\nGroup 2 TPR: 0.0090\nGroup 3 TPR: 0.3253\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Equalized Odds: 100%|██████████| 621/621 [00:19<00:00, 32.65it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0 TPR: 0.3203, FPR: 0.0001\nGroup 1 TPR: 0.0146, FPR: 0.0033\nGroup 2 TPR: 0.0090, FPR: 0.0003\nGroup 3 TPR: 0.3253, FPR: 0.0000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# CIFAR-10 with ResNet18","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\ndef get_dataloader(\n        batch_size=128, num_workers=5, split=\"train\", shuffle=False, augment=True\n    ):\n        if augment:\n            transforms = torchvision.transforms.Compose(\n                [\n                    torchvision.transforms.RandomHorizontalFlip(),\n                    torchvision.transforms.RandomAffine(0),\n                    torchvision.transforms.ToTensor(),\n                    torchvision.transforms.Normalize(\n                        (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.201)\n                    ),\n                ]\n            )\n        else:\n            transforms = torchvision.transforms.Compose(\n                [\n                    torchvision.transforms.ToTensor(),\n                    torchvision.transforms.Normalize(\n                        (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.201)\n                    ),\n                ]\n            )\n\n        is_train = split == \"train\"\n        dataset = torchvision.datasets.CIFAR10(\n            root=\"/tmp/cifar/\", download=True, train=is_train, transform=transforms\n        )\n\n        loader = torch.utils.data.DataLoader(\n            dataset=dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers\n        )\n\n        return loader\n\n# Load pre-trained model\nmodel_before_mitigating = torchvision.models.resnet18(pretrained=True).cuda()\nmodel_before_mitigating.eval()  # Set model to evaluation mode\n\n# Define loss function and optimizer (if training)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_before_mitigating.parameters(), lr=0.001, momentum=0.9)\n\n# Get data loaders\ntrain_loader = get_dataloader(batch_size=32, split=\"train\")\nval_loader = get_dataloader(batch_size=32, split=\"val\", shuffle=False, augment=False)\n\n# Training loop\nnum_epochs = 10  # Adjust as needed\nfor epoch in range(num_epochs):\n    model_before_mitigating.train()  # Set model to training mode\n    for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n        images = images.cuda()\n        labels = labels.cuda()\n\n        # Forward pass\n        outputs = model_before_mitigating(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    model_before_mitigating.eval()  # Set model to evaluation mode\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n            images = images.cuda()\n            labels = labels.cuda()\n            outputs = model_before_mitigating(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Epoch {epoch+1}, Accuracy: {accuracy:.2f}%\")\n    \n# model_before_mitigating = torchvision.models.resnet18(pretrained=True).cuda().eval()\n\n# #  put some random init weights as a placeholder\n# ckpts = [model_before_mitigating.state_dict()]\n\n# train_loader = get_dataloader(batch_size=64)\n# val_loader = get_dataloader(split=\"val\", batch_size=64)\n\n#  random group allocations as a placeholder\nckpts = [model_before_mitigating.state_dict()]\ngroup_inds = [np.random.choice(10) for i in range(len(val_loader.dataset))]\n# print(f'ckpts; {ckpts}')\n# print(f'group indicis; {group_inds}')","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-01-02T20:47:42.388294Z","iopub.status.idle":"2025-01-02T20:47:42.388652Z","shell.execute_reply":"2025-01-02T20:47:42.388499Z"},"_kg_hide-input":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# COMPAS with ResNet18","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Load COMPAS dataset\ncompas_data_path = \"/kaggle/input/compas-scores-two-years/compas-scores-two-years.csv\"  # Replace with actual path\ndf = pd.read_csv(compas_data_path)\n\n# Drop irrelevant columns\ncolumns_to_drop = [\n    \"name\", \"compas_screening_date\", \"dob\", \"c_case_number\",  # Personal identifiers\n    \"is_violent_recid\", \"is_recid\", \"c_charge_desc\"           # Other non-numeric data\n]\ndf = df.drop(columns=columns_to_drop, errors=\"ignore\")  # Ignore missing columns\n\n# Separate features and labels\nlabels = df[\"two_year_recid\"]  # Target variable\nfeatures = df.drop(columns=[\"two_year_recid\"], errors=\"ignore\")  # Drop target column from features\n\n# Filter numerical features without missing values\nnumerical_features = features.select_dtypes(include=[np.number]).dropna(axis=1)\n\n# Encode categorical features (e.g., race, sex)\ncategorical_features = features.select_dtypes(include=[\"object\", \"category\"])\ncategorical_features = pd.get_dummies(categorical_features, drop_first=True)\n\n# Combine processed numerical and categorical features\nfeatures = pd.concat([numerical_features, categorical_features], axis=1)\n\n# Normalize numerical features\nscaler = StandardScaler()\nfeatures = scaler.fit_transform(features)\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n\n# Define COMPAS Dataset Class\nclass COMPASDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.data[idx], dtype=torch.float32)\n        y = torch.tensor(self.labels[idx], dtype=torch.long)\n        return x, y\n\n# Define DataLoader Function\ndef get_compas_dataloader(batch_size=128, split=\"train\", shuffle=False):\n    \"\"\"\n    Get DataLoader for the COMPAS dataset.\n    \"\"\"\n    if split == \"train\":\n        dataset = COMPASDataset(X_train, y_train.values)\n    else:\n        dataset = COMPASDataset(X_val, y_val.values)\n\n    # DataLoader\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n    return loader, len(dataset)\n\n# Load simplified model (for tabular data)\nclass COMPASModel(nn.Module):\n    def __init__(self, input_size):\n        super(COMPASModel, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(input_size, 16),\n            nn.ReLU(),\n            nn.Linear(16, 2)  # Binary classification (2 classes: reoffended or not)\n        )\n\n    def forward(self, x):\n        return self.fc(x)\n\n# Define dataset and model\ntrain_loader, train_size = get_compas_dataloader(batch_size=32, split=\"train\", shuffle=True)\nval_loader, val_size = get_compas_dataloader(batch_size=32, split=\"val\", shuffle=False)\n\n# Input size depends on processed feature count\ninput_size = next(iter(train_loader))[0].shape[1]\nmodel_before_mitigating = COMPASModel(input_size).cuda()\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_before_mitigating.parameters(), lr=0.01, momentum=0.9)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model_before_mitigating.train()\n    epoch_loss = 0\n    with tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False) as pbar:\n        for inputs, labels in pbar:\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n\n            # Forward pass\n            outputs = model_before_mitigating(inputs)\n            loss = criterion(outputs, labels)\n            epoch_loss += loss.item()\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Update progress bar\n            pbar.set_description(f\"Epoch {epoch+1} Loss: {epoch_loss / len(train_loader):.4f}\")\n\n    print(f\"Epoch {epoch+1} Training Loss: {epoch_loss / len(train_loader):.4f}\")\n\n    # Validation\n    model_before_mitigating.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad(), tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False) as pbar:\n        for inputs, labels in pbar:\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            outputs = model_before_mitigating(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            accuracy = 100 * correct / total\n            pbar.set_description(f\"Validation Accuracy: {accuracy:.2f}%\")\n\n    print(f\"Epoch {epoch+1} Validation Accuracy: {accuracy:.2f}%\")\n\n# Define group indices based on race\nrace_mapping = {\"African-American\": 0, \"Caucasian\": 1, \"Other\": 2}\ngroup_inds = df[\"race\"].map(race_mapping).fillna(2).values  # Default to 'Other' if missing\ngroup_inds = group_inds[:len(X_val)]  # Align with validation dataset size\n\n# Print message to confirm completion\nprint(\"Training and evaluation completed.\")\nprint(f\"Group Indices (Sample): {group_inds[:10]}\")  # Print sample group indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:11:32.120612Z","iopub.execute_input":"2025-01-04T21:11:32.120964Z","iopub.status.idle":"2025-01-04T21:11:58.155335Z","shell.execute_reply.started":"2025-01-04T21:11:32.120934Z","shell.execute_reply":"2025-01-04T21:11:58.154456Z"}},"outputs":[{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Training Loss: 0.3058\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Validation Accuracy: 93.62%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Training Loss: 0.0158\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Validation Accuracy: 94.04%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Training Loss: 0.0042\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Validation Accuracy: 93.97%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Training Loss: 0.0039\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Validation Accuracy: 94.04%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Training Loss: 0.0038\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Validation Accuracy: 94.04%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Training Loss: 0.0037\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Validation Accuracy: 93.90%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Training Loss: 0.0037\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Validation Accuracy: 93.76%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Training Loss: 0.0036\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Validation Accuracy: 93.62%\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Training Loss: 0.0036\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Validation Accuracy: 93.69%\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Training Loss: 0.0037\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Validation Accuracy: 93.69%\nTraining and evaluation completed.\nGroup Indices (Sample): [2. 0. 0. 0. 2. 2. 1. 2. 1. 1.]\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"print('YOYO')\nckpts = [model_before_mitigating.state_dict()]\ndda = DDA(model_before_mitigating, ckpts, train_loader, val_loader, group_inds)\n\n# debiased_inds = dda.debias()\n# print(dda.trak_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:06:50.496937Z","iopub.execute_input":"2025-01-04T21:06:50.497303Z","iopub.status.idle":"2025-01-04T21:08:01.532751Z","shell.execute_reply.started":"2025-01-04T21:06:50.497273Z","shell.execute_reply":"2025-01-04T21:08:01.531941Z"}},"outputs":[{"name":"stdout","text":"YOYO\n","output_type":"stream"},{"name":"stderr","text":"Finalizing features for all model IDs..: 100%|██████████| 1/1 [00:00<00:00, 6384.02it/s]\nFinalizing scores for all model IDs..: 100%|██████████| 1/1 [00:00<00:00, 40.46it/s]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# debiased_inds = dda.debias(use_heuristic=False, num_to_discard=400)\ndebiased_inds = dda.debias(use_heuristic=True)\nlen(debiased_inds)\n# debiased_inds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:31.329218Z","iopub.execute_input":"2025-01-04T21:08:31.329527Z","iopub.status.idle":"2025-01-04T21:08:31.528111Z","shell.execute_reply.started":"2025-01-04T21:08:31.329503Z","shell.execute_reply":"2025-01-04T21:08:31.527214Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"2882"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport torch\n\ndef evaluate_overall_accuracy(model, val_loader, device=\"cuda\"):\n    model.eval()  # Set the model to evaluation mode\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Predict using the model\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Collect all predictions and labels\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    # Compute overall accuracy\n    accuracy = accuracy_score(all_labels, all_preds)\n    return accuracy\n\n# Example usage\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Evaluating Overall Accuracy for the first model...\")\noverall_accuracy = evaluate_overall_accuracy(model_before_mitigating, val_loader, device=device)\nprint(f\"Overall Accuracy: {overall_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:34.459337Z","iopub.execute_input":"2025-01-04T21:08:34.459615Z","iopub.status.idle":"2025-01-04T21:08:34.599568Z","shell.execute_reply.started":"2025-01-04T21:08:34.459594Z","shell.execute_reply":"2025-01-04T21:08:34.598786Z"}},"outputs":[{"name":"stdout","text":"Evaluating Overall Accuracy for the first model...\nOverall Accuracy: 0.9390\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"# Calculate WGA before intervention","metadata":{}},{"cell_type":"code","source":"# group_inds = [np.random.choice(10) for i in range(len(val_loader.dataset))]\n# Check alignment of group_inds and dataset\nassert len(group_inds) == len(val_loader.dataset), \"Group indices length mismatch.\"\nprint(f\"Group Distribution: {dict(zip(*np.unique(group_inds, return_counts=True)))}\")\n\n# Evaluate Worst Group Accuracy\nprint(\"Evaluating Worst Group Accuracy (WGA) for the first model...\")\nworst_group_acc, group_accuracies = evaluate_worst_group_accuracy(model_before_mitigating, val_loader, group_inds, device=\"cuda\")\n\nprint(f\"Group Accuracies: {group_accuracies}\")\nprint(f\"Worst Group Accuracy: {worst_group_acc:.4f}\")\nprint(f\"Difference between Worst and Best Group: {(max(group_accuracies.values()) - worst_group_acc):.4f}\")\n\nimport copy\n\ndeep_copy_model = copy.deepcopy(model_before_mitigating)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:38.030661Z","iopub.execute_input":"2025-01-04T21:08:38.030970Z","iopub.status.idle":"2025-01-04T21:08:38.209398Z","shell.execute_reply.started":"2025-01-04T21:08:38.030944Z","shell.execute_reply":"2025-01-04T21:08:38.208454Z"}},"outputs":[{"name":"stdout","text":"Group Distribution: {0.0: 728, 1.0: 485, 2.0: 230}\nEvaluating Worst Group Accuracy (WGA) for the first model...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 278.22it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.9368\nGroup 1.0 Accuracy: 0.9443\nGroup 2.0 Accuracy: 0.9348\nGroup Accuracies: {0.0: 0.9368131868131868, 1.0: 0.9443298969072165, 2.0: 0.9347826086956522}\nWorst Group Accuracy: 0.9348\nDifference between Worst and Best Group: 0.0095\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# Equal Opportunity","metadata":{}},{"cell_type":"code","source":"def calculate_tpr(labels, preds):\n    tp = np.sum((preds == 1) & (labels == 1))\n    fn = np.sum((preds == 0) & (labels == 1))\n    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\n\ndef evaluate_equal_opportunity(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval()\n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(val_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n                group_labels[group].append(labels.cpu().numpy()[i])\n\n    group_tprs = {}\n    for group in group_preds.keys():\n        preds = np.array(group_preds[group])\n        labels = np.array(group_labels[group])\n        group_tprs[group] = calculate_tpr(labels, preds)\n\n    min_tpr = min(group_tprs.values())\n    max_tpr = max(group_tprs.values())\n    tpr_disparity = max_tpr - min_tpr\n\n    return group_tprs, tpr_disparity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:47.451337Z","iopub.execute_input":"2025-01-04T21:08:47.451636Z","iopub.status.idle":"2025-01-04T21:08:47.458463Z","shell.execute_reply.started":"2025-01-04T21:08:47.451612Z","shell.execute_reply":"2025-01-04T21:08:47.457663Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"group_tprs, tpr_disparity = evaluate_equal_opportunity(deep_copy_model, val_loader, group_inds)\nprint(f\"Group TPRs: {group_tprs}\")\nprint(f\"TPR Disparity: {tpr_disparity:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:49.370475Z","iopub.execute_input":"2025-01-04T21:08:49.370758Z","iopub.status.idle":"2025-01-04T21:08:49.538616Z","shell.execute_reply.started":"2025-01-04T21:08:49.370735Z","shell.execute_reply":"2025-01-04T21:08:49.537695Z"}},"outputs":[{"name":"stdout","text":"Group TPRs: {0.0: 0.9013157894736842, 1.0: 0.8986175115207373, 2.0: 0.898989898989899}\nTPR Disparity: 0.0027\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# Equal Odds","metadata":{}},{"cell_type":"code","source":"def calculate_fpr(labels, preds):\n    fp = np.sum((preds == 1) & (labels == 0))\n    tn = np.sum((preds == 0) & (labels == 0))\n    return fp / (fp + tn) if (fp + tn) > 0 else 0.0\n\ndef evaluate_equalized_odds(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval()\n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(val_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n                group_labels[group].append(labels.cpu().numpy()[i])\n\n    group_tprs, group_fprs = {}, {}\n    for group in group_preds.keys():\n        preds = np.array(group_preds[group])\n        labels = np.array(group_labels[group])\n        group_tprs[group] = calculate_tpr(labels, preds)\n        group_fprs[group] = calculate_fpr(labels, preds)\n\n    tpr_disparity = max(group_tprs.values()) - min(group_tprs.values())\n    fpr_disparity = max(group_fprs.values()) - min(group_fprs.values())\n\n    return group_tprs, group_fprs, tpr_disparity, fpr_disparity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:51.942808Z","iopub.execute_input":"2025-01-04T21:08:51.943110Z","iopub.status.idle":"2025-01-04T21:08:51.950520Z","shell.execute_reply.started":"2025-01-04T21:08:51.943088Z","shell.execute_reply":"2025-01-04T21:08:51.949566Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"group_tprs, group_fprs, tpr_disparity, fpr_disparity = evaluate_equalized_odds(deep_copy_model, val_loader, group_inds)\nprint(f\"Group TPRs: {group_tprs}\")\nprint(f\"Group FPRs: {group_fprs}\")\nprint(f\"TPR Disparity: {tpr_disparity:.4f}\")\nprint(f\"FPR Disparity: {fpr_disparity:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:54.083677Z","iopub.execute_input":"2025-01-04T21:08:54.083996Z","iopub.status.idle":"2025-01-04T21:08:54.258662Z","shell.execute_reply.started":"2025-01-04T21:08:54.083969Z","shell.execute_reply":"2025-01-04T21:08:54.257856Z"}},"outputs":[{"name":"stdout","text":"Group TPRs: {0.0: 0.9013157894736842, 1.0: 0.8986175115207373, 2.0: 0.898989898989899}\nGroup FPRs: {0.0: 0.03773584905660377, 1.0: 0.018656716417910446, 2.0: 0.03816793893129771}\nTPR Disparity: 0.0027\nFPR Disparity: 0.0195\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"# Demographic Parity","metadata":{}},{"cell_type":"code","source":"def calculate_ppr(preds):\n    return np.mean(preds)\n\n\ndef evaluate_demographic_parity(model, val_loader, group_inds, device=\"cuda\"):\n    \"\"\"\n    Evaluate Demographic Parity.\n    Ensures PPR is correctly normalized as probabilities.\n    \"\"\"\n    model.eval()\n    group_preds = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(val_loader):\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Get the group indices for the current batch\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            # Assign predictions to the corresponding group\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n\n    group_pprs = {}\n    for group in group_preds.keys():\n        # Flatten the predictions list for each group and normalize\n        preds = np.array(group_preds[group]).flatten()\n        positive_preds = (preds == 1).sum()  # Count positive predictions\n        total_preds = len(preds)  # Total number of predictions\n        group_pprs[group] = positive_preds / total_preds if total_preds > 0 else 0.0\n\n    # Calculate the disparity in PPRs across groups\n    min_ppr = min(group_pprs.values())\n    max_ppr = max(group_pprs.values())\n    ppr_disparity = max_ppr - min_ppr\n\n    return group_pprs, ppr_disparity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:08:58.602054Z","iopub.execute_input":"2025-01-04T21:08:58.602359Z","iopub.status.idle":"2025-01-04T21:08:58.608674Z","shell.execute_reply.started":"2025-01-04T21:08:58.602334Z","shell.execute_reply":"2025-01-04T21:08:58.607796Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"group_pprs, ppr_disparity = evaluate_demographic_parity(deep_copy_model, val_loader, group_inds)\nprint(f\"Group PPRs: {group_pprs}\")\nprint(f\"PPR Disparity: {ppr_disparity:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:09:00.526359Z","iopub.execute_input":"2025-01-04T21:09:00.526662Z","iopub.status.idle":"2025-01-04T21:09:00.673358Z","shell.execute_reply.started":"2025-01-04T21:09:00.526639Z","shell.execute_reply":"2025-01-04T21:09:00.672386Z"}},"outputs":[{"name":"stdout","text":"Group PPRs: {0.0: 0.3983516483516483, 1.0: 0.41237113402061853, 2.0: 0.40869565217391307}\nPPR Disparity: 0.0140\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# False Negative for COMPAS dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom tqdm import tqdm\n\ndef calculate_fnr_fpr(model, val_loader, group_inds, device=\"cuda\"):\n    \"\"\"\n    Calculate False Negative Rate (FNR) and False Positive Rate (FPR) for each group.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n    group_metrics = {g: {\"FN\": 0, \"FP\": 0, \"TP\": 0, \"TN\": 0} for g in set(group_inds)}  # Metrics for each group\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader, desc=\"Calculating FNR and FPR\")):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            labels = labels.cpu().numpy()\n\n            # Get the groups for the current batch\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                if group not in group_metrics:\n                    continue  # Skip if group is not defined\n                \n                # Update confusion matrix components\n                if labels[i] == 1 and preds[i] == 0:  # False Negative\n                    group_metrics[group][\"FN\"] += 1\n                elif labels[i] == 0 and preds[i] == 1:  # False Positive\n                    group_metrics[group][\"FP\"] += 1\n                elif labels[i] == 1 and preds[i] == 1:  # True Positive\n                    group_metrics[group][\"TP\"] += 1\n                elif labels[i] == 0 and preds[i] == 0:  # True Negative\n                    group_metrics[group][\"TN\"] += 1\n\n    # Calculate FNR and FPR for each group\n    group_fnr_fpr = {}\n    for group, metrics in group_metrics.items():\n        fn = metrics[\"FN\"]\n        fp = metrics[\"FP\"]\n        tp = metrics[\"TP\"]\n        tn = metrics[\"TN\"]\n\n        actual_positives = tp + fn\n        actual_negatives = tn + fp\n\n        fnr = fn / (actual_positives + 1e-8) if actual_positives > 0 else 0.0\n        fpr = fp / (actual_negatives + 1e-8) if actual_negatives > 0 else 0.0\n\n        group_fnr_fpr[group] = {\"FNR\": fnr, \"FPR\": fpr}\n\n    # Print FNR and FPR for each group\n    print(\"\\nGroup FNR and FPR:\")\n    for group, metrics in group_fnr_fpr.items():\n        print(f\"Group {group}: FNR = {metrics['FNR']:.4f}, FPR = {metrics['FPR']:.4f}\")\n\n    # Calculate and print disparities\n    fnr_values = [metrics[\"FNR\"] for metrics in group_fnr_fpr.values()]\n    fpr_values = [metrics[\"FPR\"] for metrics in group_fnr_fpr.values()]\n    fnr_disparity = max(fnr_values) - min(fnr_values)\n    fpr_disparity = max(fpr_values) - min(fpr_values)\n\n    print(f\"\\nFNR Disparity (Max - Min): {fnr_disparity:.4f}\")\n    print(f\"FPR Disparity (Max - Min): {fpr_disparity:.4f}\")\n\n    return group_fnr_fpr, fnr_disparity, fpr_disparity\n\n\n# Example usage\ngroup_fnr_fpr, fnr_disparity, fpr_disparity = calculate_fnr_fpr(model_before_mitigating, val_loader, group_inds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T21:09:03.330463Z","iopub.execute_input":"2025-01-04T21:09:03.330777Z","iopub.status.idle":"2025-01-04T21:09:03.487764Z","shell.execute_reply.started":"2025-01-04T21:09:03.330745Z","shell.execute_reply":"2025-01-04T21:09:03.486866Z"}},"outputs":[{"name":"stderr","text":"Calculating FNR and FPR: 100%|██████████| 46/46 [00:00<00:00, 323.07it/s]","output_type":"stream"},{"name":"stdout","text":"\nGroup FNR and FPR:\nGroup 0.0: FNR = 0.0987, FPR = 0.0377\nGroup 1.0: FNR = 0.1014, FPR = 0.0187\nGroup 2.0: FNR = 0.1010, FPR = 0.0382\n\nFNR Disparity (Max - Min): 0.0027\nFPR Disparity (Max - Min): 0.0195\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"# Machine Unlearning","metadata":{}},{"cell_type":"code","source":"harmful_indices = debiased_inds\n\ndef remove_influence(model, dataloader, harmful_indices, factor, device=\"cuda\"):\n    model.eval()\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    for inputs, labels in harmful_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(model.parameters(), grads):\n                param -= grad * factor\n\n    return model\n\nresults ={'factor':[], 'model':[], 'min':[], 'max':[], 'gap':[]}\nfactors = np.linspace(0.0001, 0.01, 20)\n\nfor factor in factors:\n    newdeepmodel = copy.deepcopy(deep_copy_model)\n    m = remove_influence(newdeepmodel, train_loader, harmful_indices, factor, device=\"cuda\")\n    wga, group_accs = evaluate_worst_group_accuracy(m, val_loader, group_inds, device=\"cuda\")\n    current_gap = (max(group_accs.values()) - wga)\n    results['model'].append(m)\n    results['min'].append(wga)\n    results['max'].append(max(group_accs.values()))\n    results['gap'].append(current_gap)\n    results['factor'].append(factor)   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:43:15.730681Z","iopub.execute_input":"2025-01-04T20:43:15.730961Z","iopub.status.idle":"2025-01-04T20:45:20.139691Z","shell.execute_reply.started":"2025-01-04T20:43:15.730940Z","shell.execute_reply":"2025-01-04T20:45:20.138847Z"}},"outputs":[{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 697.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7047\nGroup 1.0 Accuracy: 0.6680\nGroup 2.0 Accuracy: 0.6957\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 699.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7033\nGroup 1.0 Accuracy: 0.6742\nGroup 2.0 Accuracy: 0.6913\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 694.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7005\nGroup 1.0 Accuracy: 0.6784\nGroup 2.0 Accuracy: 0.6913\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 680.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6964\nGroup 1.0 Accuracy: 0.6784\nGroup 2.0 Accuracy: 0.6870\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 695.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7019\nGroup 1.0 Accuracy: 0.6742\nGroup 2.0 Accuracy: 0.6826\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 703.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7033\nGroup 1.0 Accuracy: 0.6742\nGroup 2.0 Accuracy: 0.6826\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 694.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7033\nGroup 1.0 Accuracy: 0.6722\nGroup 2.0 Accuracy: 0.6783\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 681.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6992\nGroup 1.0 Accuracy: 0.6680\nGroup 2.0 Accuracy: 0.6826\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 681.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6978\nGroup 1.0 Accuracy: 0.6742\nGroup 2.0 Accuracy: 0.6783\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 681.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7019\nGroup 1.0 Accuracy: 0.6680\nGroup 2.0 Accuracy: 0.6739\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 687.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7033\nGroup 1.0 Accuracy: 0.6660\nGroup 2.0 Accuracy: 0.6696\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 691.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7019\nGroup 1.0 Accuracy: 0.6619\nGroup 2.0 Accuracy: 0.6609\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 696.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6992\nGroup 1.0 Accuracy: 0.6680\nGroup 2.0 Accuracy: 0.6652\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 701.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6964\nGroup 1.0 Accuracy: 0.6557\nGroup 2.0 Accuracy: 0.6652\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 673.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6992\nGroup 1.0 Accuracy: 0.6557\nGroup 2.0 Accuracy: 0.6609\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 698.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6964\nGroup 1.0 Accuracy: 0.6557\nGroup 2.0 Accuracy: 0.6609\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 703.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6964\nGroup 1.0 Accuracy: 0.6536\nGroup 2.0 Accuracy: 0.6609\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 701.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6937\nGroup 1.0 Accuracy: 0.6495\nGroup 2.0 Accuracy: 0.6565\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 705.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.6978\nGroup 1.0 Accuracy: 0.6495\nGroup 2.0 Accuracy: 0.6565\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 706.27it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0.0 Accuracy: 0.7005\nGroup 1.0 Accuracy: 0.6598\nGroup 2.0 Accuracy: 0.6609\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(results).sort_values('factor')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:45:20.140693Z","iopub.execute_input":"2025-01-04T20:45:20.140960Z","iopub.status.idle":"2025-01-04T20:45:20.154346Z","shell.execute_reply.started":"2025-01-04T20:45:20.140935Z","shell.execute_reply":"2025-01-04T20:45:20.153542Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"      factor                                              model       min  \\\n0   0.000100  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.668041   \n1   0.000621  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n2   0.001142  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.678351   \n3   0.001663  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.678351   \n4   0.002184  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n5   0.002705  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n6   0.003226  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.672165   \n7   0.003747  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.668041   \n8   0.004268  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n9   0.004789  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.668041   \n10  0.005311  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.665979   \n11  0.005832  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.660870   \n12  0.006353  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.665217   \n13  0.006874  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.655670   \n14  0.007395  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.655670   \n15  0.007916  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.655670   \n16  0.008437  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.653608   \n17  0.008958  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.649485   \n18  0.009479  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.649485   \n19  0.010000  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.659794   \n\n         max       gap  \n0   0.704670  0.036629  \n1   0.703297  0.029070  \n2   0.700549  0.022199  \n3   0.696429  0.018078  \n4   0.701923  0.027696  \n5   0.703297  0.029070  \n6   0.703297  0.031132  \n7   0.699176  0.031135  \n8   0.697802  0.023575  \n9   0.701923  0.033882  \n10  0.703297  0.037317  \n11  0.701923  0.041054  \n12  0.699176  0.033958  \n13  0.696429  0.040758  \n14  0.699176  0.043506  \n15  0.696429  0.040758  \n16  0.696429  0.042820  \n17  0.693681  0.044197  \n18  0.697802  0.048318  \n19  0.700549  0.040756  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>factor</th>\n      <th>model</th>\n      <th>min</th>\n      <th>max</th>\n      <th>gap</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000100</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.668041</td>\n      <td>0.704670</td>\n      <td>0.036629</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000621</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.674227</td>\n      <td>0.703297</td>\n      <td>0.029070</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.001142</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.678351</td>\n      <td>0.700549</td>\n      <td>0.022199</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001663</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.678351</td>\n      <td>0.696429</td>\n      <td>0.018078</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.002184</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.674227</td>\n      <td>0.701923</td>\n      <td>0.027696</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.002705</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.674227</td>\n      <td>0.703297</td>\n      <td>0.029070</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.003226</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.672165</td>\n      <td>0.703297</td>\n      <td>0.031132</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.003747</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.668041</td>\n      <td>0.699176</td>\n      <td>0.031135</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.004268</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.674227</td>\n      <td>0.697802</td>\n      <td>0.023575</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.004789</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.668041</td>\n      <td>0.701923</td>\n      <td>0.033882</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.005311</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.665979</td>\n      <td>0.703297</td>\n      <td>0.037317</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.005832</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.660870</td>\n      <td>0.701923</td>\n      <td>0.041054</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.006353</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.665217</td>\n      <td>0.699176</td>\n      <td>0.033958</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.006874</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.655670</td>\n      <td>0.696429</td>\n      <td>0.040758</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.007395</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.655670</td>\n      <td>0.699176</td>\n      <td>0.043506</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.007916</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.655670</td>\n      <td>0.696429</td>\n      <td>0.040758</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.008437</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.653608</td>\n      <td>0.696429</td>\n      <td>0.042820</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.008958</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.649485</td>\n      <td>0.693681</td>\n      <td>0.044197</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.009479</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.649485</td>\n      <td>0.697802</td>\n      <td>0.048318</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.010000</td>\n      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n      <td>0.659794</td>\n      <td>0.700549</td>\n      <td>0.040756</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"Now, it's time to investigate what are the best approaches to machine unlearning and how can we formulate that.","metadata":{}},{"cell_type":"markdown","source":"What are the other approaches to machine unlearning?","metadata":{}},{"cell_type":"markdown","source":"Other Fairness notations might come in handy!","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
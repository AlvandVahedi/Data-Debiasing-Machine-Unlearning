{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"pip install traker","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trak import TRAKer\n\ndef get_trak_matrix(\n    train_dl, val_dl, model, ckpts, train_set_size, val_set_size, **kwargs\n):\n    if kwargs is None or kwargs.get(\"task\") is None:\n        task = \"image_classification\"\n    else:\n        task = kwargs.pop(\"task\")\n\n    traker = TRAKer(model=model, task=task, train_set_size=train_set_size, **kwargs)\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.load_checkpoint(checkpoint, model_id=model_id)\n        for batch in train_dl:\n            batch = [x.cuda() for x in batch]\n            # batch should be a tuple/list of inputs and labels\n            traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n\n    traker.finalize_features()\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.start_scoring_checkpoint(\n            exp_name=\"test\",\n            checkpoint=checkpoint,\n            model_id=model_id,\n            num_targets=val_set_size,\n        )\n    for batch in val_dl:\n        batch = [x.cuda() for x in batch]\n        traker.score(batch=batch, num_samples=batch[0].shape[0])\n\n    scores = traker.finalize_scores(exp_name=\"test\")\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2025-01-07T04:49:07.802546Z","iopub.execute_input":"2025-01-07T04:49:07.802883Z","iopub.status.idle":"2025-01-07T04:49:07.809976Z","shell.execute_reply.started":"2025-01-07T04:49:07.802857Z","shell.execute_reply":"2025-01-07T04:49:07.809122Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.nn import functional as F\n\nclass DDA:\n    def __init__(\n        self,\n        model,\n        checkpoints,\n        train_dataloader,\n        val_dataloader,\n        group_indices,\n        train_set_size=None,\n        val_set_size=None,\n        trak_scores=None,\n        trak_kwargs=None,\n        device=\"cuda\",\n    ) -> None:\n        \n        self.model = model\n        self.checkpoints = checkpoints\n        self.dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n        self.group_indices = group_indices\n        self.device = device\n\n        if trak_scores is not None:\n            self.trak_scores = trak_scores\n        else:\n            try:\n                self.train_set_size = len(train_dataloader.dataset)\n                self.val_set_size = len(val_dataloader.dataset)\n            except AttributeError as e:\n                print(\n                    f\"No dataset attribute found in train_dataloader or val_dataloader. {e}\"\n                )\n                if train_set_size is None or val_set_size is None:\n                    raise ValueError(\n                        \"train_set_size and val_set_size must be specified if \"\n                        \"train_dataloader and val_dataloader do not have a \"\n                        \"dataset attribute.\"\n                    ) from e\n                self.train_set_size = train_set_size\n                self.val_set_size = val_set_size\n\n            # Step 1: compute TRAK scores\n            if trak_kwargs is not None:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                    **trak_kwargs,\n                )\n            else:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                )\n\n            self.trak_scores = trak_scores\n\n    def get_group_losses(self, model, val_dl, group_indices) -> list:\n        losses = []\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in val_dl:\n                outputs = model(inputs.to(self.device))\n                loss = F.cross_entropy(\n                    outputs, labels.to(self.device), reduction=\"none\"\n                )\n                losses.append(loss)\n        losses = torch.cat(losses)\n\n        n_groups = len(set(group_indices))\n        group_losses = [losses[group_indices == i].mean() for i in range(n_groups)]\n        return group_losses\n\n    def compute_group_alignment_scores(self, trak_scores, group_indices, group_losses):\n        n_groups = len(set(group_indices))\n        S = np.array(trak_scores)\n        g = [\n            group_losses[i].cpu().numpy() * S[:, np.array(group_indices) == i].mean(axis=1)\n            for i in range(n_groups)\n        ]\n        g = np.stack(g)\n        group_alignment_scores = g.mean(axis=0)\n        return group_alignment_scores\n\n    def get_debiased_train_indices(\n        self, group_alignment_scores, use_heuristic=True, num_to_discard=None\n    ):\n        if use_heuristic:\n            return [i for i, score in enumerate(group_alignment_scores) if score >= 0]\n\n        if num_to_discard is None:\n            raise ValueError(\"num_to_discard must be specified if not using heuristic.\")\n\n        sorted_indices = sorted(\n            range(len(group_alignment_scores)),\n            key=lambda i: group_alignment_scores[i],\n        )\n        return sorted_indices[num_to_discard:]\n\n    def debias(self, use_heuristic=True, num_to_discard=None):\n        group_losses = self.get_group_losses(\n            model=self.model,\n            val_dl=self.dataloaders[\"val\"],\n            group_indices=self.group_indices,\n        )\n\n        group_alignment_scores = self.compute_group_alignment_scores(\n            self.trak_scores, self.group_indices, group_losses\n        )\n        \n        debiased_train_inds = self.get_debiased_train_indices(\n            group_alignment_scores,\n            use_heuristic=use_heuristic,\n            num_to_discard=num_to_discard,\n        )\n\n        return debiased_train_inds\n","metadata":{"execution":{"iopub.status.busy":"2025-01-07T04:49:10.808017Z","iopub.execute_input":"2025-01-07T04:49:10.808322Z","iopub.status.idle":"2025-01-07T04:49:10.820673Z","shell.execute_reply.started":"2025-01-07T04:49:10.808297Z","shell.execute_reply":"2025-01-07T04:49:10.819898Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"execution":{"iopub.status.busy":"2025-01-07T04:49:15.914066Z","iopub.execute_input":"2025-01-07T04:49:15.914361Z","iopub.status.idle":"2025-01-07T04:49:15.917906Z","shell.execute_reply.started":"2025-01-07T04:49:15.914338Z","shell.execute_reply":"2025-01-07T04:49:15.917019Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"# CelebA","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Subset\nfrom tqdm import tqdm\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\n\n# Paths to CelebA images and metadata\nceleba_images_path = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\npartition_file = \"/kaggle/input/celeba-dataset/list_eval_partition.csv\"\nattributes_file = \"/kaggle/input/celeba-dataset/list_attr_celeba.csv\"\n\n# Function to get DataLoader for CelebA\ndef get_dataloader(\n        batch_size=128, num_workers=4, split=\"train\", shuffle=False, augment=True\n    ):\n    \"\"\"\n    Get DataLoader for the CelebA dataset.\n    \"\"\"\n    # Define transformations\n    if augment:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.RandomHorizontalFlip(),\n                transforms.CenterCrop(178),  # Crop central face region\n                transforms.Resize(128),  # Resize to smaller dimensions\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),  # Normalize to [-1, 1]\n            ]\n        )\n    else:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n\n    # Load partition and attributes\n    partitions = pd.read_csv(partition_file)\n    attributes = pd.read_csv(attributes_file)\n\n    # Ensure attributes are binary\n    attributes.iloc[:, 1:] = attributes.iloc[:, 1:].applymap(lambda x: 1 if x == 1 else 0)\n\n    # Define young (attribute \"Young\") and old classes\n    young_indices = attributes[attributes[\"Young\"] == 1].index\n    old_indices = attributes[attributes[\"Young\"] == 0].index\n\n    # Create the subset with a 4:1 ratio (young:old)\n    num_old = len(old_indices)\n    num_young = min(len(young_indices), num_old * 4)\n    selected_young_indices = np.random.choice(young_indices, num_young, replace=False)\n    selected_indices = np.concatenate([selected_young_indices, old_indices])\n\n    # Split the subset based on train/val partitions\n    dataset_split = \"train\" if split == \"train\" else \"valid\"\n    if dataset_split == \"train\":\n        selected_indices = partitions[(partitions[\"partition\"] == 0) & partitions.index.isin(selected_indices)].index\n    else:\n        selected_indices = partitions[(partitions[\"partition\"] == 1) & partitions.index.isin(selected_indices)].index\n\n    # Custom Dataset class for CelebA\n    class CelebADataset(torch.utils.data.Dataset):\n        def __init__(self, indices, img_dir, attributes, transform=None):\n            self.indices = indices\n            self.img_dir = img_dir\n            self.attributes = attributes\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.indices)\n\n        def __getitem__(self, idx):\n            img_index = self.indices[idx]\n            img_name = self.attributes.iloc[img_index, 0]  # Image file name\n            img_path = os.path.join(self.img_dir, img_name)\n\n            # Load and preprocess the image\n            image = Image.open(img_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n\n            # Binary class label: young (1) or old (0)\n            label = torch.tensor(self.attributes.iloc[img_index][\"Young\"], dtype=torch.long)\n            return image, label\n\n    # Create Dataset and DataLoader\n    dataset = CelebADataset(\n        indices=selected_indices,\n        img_dir=celeba_images_path,\n        attributes=attributes,\n        transform=transforms_pipeline\n    )\n\n    loader = DataLoader(\n        dataset=dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers\n    )\n\n    return loader, dataset\n\n# Load pre-trained model\nfrom torchvision.models import resnet18, ResNet18_Weights\nmodel_before_mitigating = resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel_before_mitigating.fc = nn.Linear(model_before_mitigating.fc.in_features, 2)  # Binary classification (young or old)\nmodel_before_mitigating = model_before_mitigating.cuda()\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Get DataLoaders\ntrain_loader, train_dataset = get_dataloader(batch_size=32, split=\"train\", shuffle=True)\nval_loader, val_dataset = get_dataloader(batch_size=32, split=\"val\", shuffle=False, augment=False)\n\n# Training Loop\nnum_epochs = 4\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    model.train()\n    epoch_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=\"Training\"):\n        images = images.cuda()\n        labels = labels.cuda()\n\n        # Forward pass\n        outputs = model_before_mitigating(images)\n        loss = criterion(outputs, labels)\n        epoch_loss += loss.item()\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Training Loss: {avg_loss:.4f}\")\n\n    # Validation\n    model_before_mitigating.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n            images = images.cuda()\n            labels = labels.cuda()\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n\n# Final Output\nprint(\"Training and evaluation completed.\")","metadata":{"execution":{"iopub.status.busy":"2025-01-07T04:49:25.215098Z","iopub.execute_input":"2025-01-07T04:49:25.215404Z"},"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-34-99c256910e25>:50: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  attributes.iloc[:, 1:] = attributes.iloc[:, 1:].applymap(lambda x: 1 if x == 1 else 0)\n<ipython-input-34-99c256910e25>:50: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  attributes.iloc[:, 1:] = attributes.iloc[:, 1:].applymap(lambda x: 1 if x == 1 else 0)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 5087/5087 [03:22<00:00, 25.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.8427\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 621/621 [00:28<00:00, 21.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 85.80%\n\nEpoch 2/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 5087/5087 [03:30<00:00, 24.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.8651\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 621/621 [00:19<00:00, 32.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 85.80%\n\nEpoch 3/4\n","output_type":"stream"},{"name":"stderr","text":"Training:  31%|███▏      | 1591/5087 [00:58<02:05, 27.79it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport numpy as np\n\ndef evaluate_worst_group_accuracy(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval()  # Set model to evaluation mode\n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating WGA\")):\n            inputs = inputs.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` since labels are not one-hot encoded\n\n            # Predict using the model\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Assign predictions and labels to the respective group\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])  # Add single prediction\n                group_labels[group].append(labels.cpu().numpy()[i])  # Add single label\n\n    group_accuracies = {}\n    for group in group_preds.keys():\n        if len(group_preds[group]) == 0 or len(group_labels[group]) == 0:\n            # Skip groups with no samples\n            group_accuracies[group] = 0.0\n            continue\n\n        # Convert lists to arrays\n        preds = np.array(group_preds[group])\n        truths = np.array(group_labels[group])\n        group_accuracies[group] = accuracy_score(truths, preds)\n\n    # Print all group accuracies\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n\n    # Find the worst group accuracy\n    worst_group_accuracy = min(group_accuracies.values())\n    return worst_group_accuracy, group_accuracies","metadata":{"execution":{"iopub.status.busy":"2025-01-07T03:14:27.833350Z","iopub.execute_input":"2025-01-07T03:14:27.833735Z","iopub.status.idle":"2025-01-07T03:14:27.844251Z","shell.execute_reply.started":"2025-01-07T03:14:27.833706Z","shell.execute_reply":"2025-01-07T03:14:27.843339Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Generate subgroup labels: young-male, young-female, old-male, old-female\nattributes = pd.read_csv(attributes_file)\n\n# Create the `group_index` column for subgroups\nattributes['Young'] = attributes['Young'].apply(lambda x: 1 if x == 1 else 0)\nattributes['Male'] = attributes['Male'].apply(lambda x: 1 if x == 1 else 0)\n\ndef define_subgroups(row):\n    if row['Young'] == 1 and row['Male'] == 1:\n        return 0  # young-male\n    elif row['Young'] == 1 and row['Male'] == 0:\n        return 1  # young-female\n    elif row['Young'] == 0 and row['Male'] == 1:\n        return 2  # old-male\n    elif row['Young'] == 0 and row['Male'] == 0:\n        return 3  # old-female\n\nattributes['group_index'] = attributes.apply(define_subgroups, axis=1)\n\n# Generate group indices for the validation dataset\ngroup_labels = attributes.loc[val_dataset.indices, 'group_index'].values\ngroup_inds = group_labels  # Align group indices with validation dataset size\n\n# Evaluate Worst Group Accuracy (WGA)\nprint(\"\\nEvaluating Worst Group Accuracy (WGA)...\")\nworst_group_accuracy, group_accuracies = evaluate_worst_group_accuracy(\n    model_before_mitigating, val_loader, group_inds, device=\"cuda\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T03:45:19.070851Z","iopub.execute_input":"2025-01-07T03:45:19.071240Z","iopub.status.idle":"2025-01-07T03:46:00.439097Z","shell.execute_reply.started":"2025-01-07T03:45:19.071212Z","shell.execute_reply":"2025-01-07T03:46:00.438140Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating Worst Group Accuracy (WGA)...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 621/621 [00:38<00:00, 16.10it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.9822\nGroup 1 Accuracy: 0.9956\nGroup 2 Accuracy: 0.5738\nGroup 3 Accuracy: 0.2457\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"**Calculating Fairness Metrics for Young and Old Groups**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\n\n# Function to evaluate Group Accuracies\ndef evaluate_group_accuracies(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_preds = {g: [] for g in set(group_labels)}\n    group_truths = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Group Accuracies\")):\n            images = images.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` here\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Assign predictions and truths to respective groups\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_preds[group].append(preds[j])\n                group_truths[group].append(labels.cpu().numpy()[j])\n\n    group_accuracies = {}\n    for group in group_preds:\n        if len(group_preds[group]) == 0:\n            group_accuracies[group] = 0.0\n        else:\n            preds = np.array(group_preds[group])\n            truths = np.array(group_truths[group])\n            group_accuracies[group] = accuracy_score(truths, preds)\n\n    # Print group accuracies\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n    \n    return group_accuracies\n\n# Function to evaluate Demographic Parity (DP)\ndef evaluate_demographic_parity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_pprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, _) in enumerate(tqdm(val_loader, desc=\"Evaluating Demographic Parity\")):\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(preds)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_pprs[group].append(preds[j])\n\n    ppr_disparities = {}\n    for group in group_pprs:\n        group_positive_rate = np.mean(group_pprs[group])\n        ppr_disparities[group] = group_positive_rate\n\n    # Print group PPRs\n    for group, ppr in ppr_disparities.items():\n        print(f\"Group {group} PPR: {ppr:.4f}\")\n    \n    return ppr_disparities\n\n# Function to evaluate Equal Opportunity (EO)\ndef evaluate_equal_opportunity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equal Opportunity\")):\n            images = images.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` here\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                actual_positive = labels[j].cpu().numpy() == 1\n                group_tprs[group].append(tp / (actual_positive + 1e-8))  # Avoid division by zero\n\n    tpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n\n    # Print group TPRs\n    for group, tpr in tpr_disparities.items():\n        print(f\"Group {group} TPR: {tpr:.4f}\")\n    \n    return tpr_disparities\n\n# Function to evaluate Equalized Odds (EOd)\ndef evaluate_equalized_odds(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n    group_fprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equalized Odds\")):\n            images = images.to(device)\n            labels = labels.to(device)  # Remove `.argmax(dim=1)` here\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                fp = (preds[j] == 1 and labels[j].cpu().numpy() == 0)\n                actual_positive = labels[j].cpu().numpy() == 1\n                actual_negative = labels[j].cpu().numpy() == 0\n\n                group_tprs[group].append(tp / (actual_positive + 1e-8))  # Avoid division by zero\n                group_fprs[group].append(fp / (actual_negative + 1e-8))  # Avoid division by zero\n\n    tpr_disparities = {}\n    fpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n        fpr_disparities[group] = np.mean(group_fprs[group])\n\n    # Print group TPRs and FPRs\n    for group in group_tprs:\n        print(f\"Group {group} TPR: {tpr_disparities[group]:.4f}, FPR: {fpr_disparities[group]:.4f}\")\n    \n    return tpr_disparities, fpr_disparities","metadata":{"execution":{"iopub.status.busy":"2025-01-07T03:56:10.980482Z","iopub.execute_input":"2025-01-07T03:56:10.980796Z","iopub.status.idle":"2025-01-07T03:56:10.996832Z","shell.execute_reply.started":"2025-01-07T03:56:10.980775Z","shell.execute_reply":"2025-01-07T03:56:10.995903Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"wga, group_accuracies = evaluate_worst_group_accuracy(model_before_mitigating, val_loader, group_labels)\ndp_rates = evaluate_demographic_parity(model_before_mitigating, val_loader, group_labels)\neo_tprs = evaluate_equal_opportunity(model_before_mitigating, val_loader, group_labels)\ntpr_disparities, fpr_disparities = evaluate_equalized_odds(model_before_mitigating, val_loader, group_labels)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T03:56:15.663001Z","iopub.execute_input":"2025-01-07T03:56:15.663330Z","iopub.status.idle":"2025-01-07T03:57:37.173601Z","shell.execute_reply.started":"2025-01-07T03:56:15.663304Z","shell.execute_reply":"2025-01-07T03:57:37.172772Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 621/621 [00:20<00:00, 30.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.9822\nGroup 1 Accuracy: 0.9956\nGroup 2 Accuracy: 0.5738\nGroup 3 Accuracy: 0.2457\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Demographic Parity: 100%|██████████| 621/621 [00:20<00:00, 30.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 PPR: 0.9822\nGroup 1 PPR: 0.9956\nGroup 2 PPR: 0.4262\nGroup 3 PPR: 0.7543\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Equal Opportunity: 100%|██████████| 621/621 [00:22<00:00, 27.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 TPR: 0.9822\nGroup 1 TPR: 0.9956\nGroup 2 TPR: 0.0000\nGroup 3 TPR: 0.0000\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Equalized Odds: 100%|██████████| 621/621 [00:18<00:00, 34.10it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0 TPR: 0.9822, FPR: 0.0000\nGroup 1 TPR: 0.9956, FPR: 0.0000\nGroup 2 TPR: 0.0000, FPR: 0.4262\nGroup 3 TPR: 0.0000, FPR: 0.7543\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# Debiasing with D3M","metadata":{}},{"cell_type":"code","source":"print('YOYO')\nckpts = [model_before_mitigating.state_dict()]\ndda = DDA(model_before_mitigating, ckpts, train_loader, val_loader, group_inds)\n\n# debiased_inds = dda.debias()\n# print(dda.trak_scores)","metadata":{"execution":{"iopub.status.busy":"2025-01-07T03:58:06.456211Z","iopub.execute_input":"2025-01-07T03:58:06.456512Z","iopub.status.idle":"2025-01-07T04:46:47.091864Z","shell.execute_reply.started":"2025-01-07T03:58:06.456490Z","shell.execute_reply":"2025-01-07T04:46:47.090084Z"},"trusted":true},"outputs":[{"name":"stdout","text":"YOYO\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-a3fe866a914e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YOYO'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mckpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_before_mitigating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_before_mitigating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# debiased_inds = dda.debias()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-fb470b2002b6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, checkpoints, train_dataloader, val_dataloader, group_indices, train_set_size, val_set_size, trak_scores, trak_kwargs, device)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 )\n\u001b[1;32m     56\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 trak_scores = get_trak_matrix(\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0mtrain_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mval_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-0086449580fa>\u001b[0m in \u001b[0;36mget_trak_matrix\u001b[0;34m(train_dl, val_dl, model, ckpts, train_set_size, val_set_size, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# batch should be a tuple/list of inputs and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtraker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtraker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trak/traker.py\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(self, batch, inds, num_samples)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         self.saver.current_store[\"grads\"][inds] = (\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":29},{"cell_type":"code","source":"# debiased_inds = dda.debias(use_heuristic=False, num_to_discard=400)\ndebiased_inds = dda.debias(use_heuristic=True)\nlen(debiased_inds)\n# debiased_inds","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:08:31.329527Z","iopub.status.busy":"2025-01-04T21:08:31.329218Z","iopub.status.idle":"2025-01-04T21:08:31.528111Z","shell.execute_reply":"2025-01-04T21:08:31.527214Z","shell.execute_reply.started":"2025-01-04T21:08:31.329503Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2882"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"execution_count":35},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport torch\n\ndef evaluate_overall_accuracy(model, val_loader, device=\"cuda\"):\n    model.eval()  # Set the model to evaluation mode\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Predict using the model\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Collect all predictions and labels\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    # Compute overall accuracy\n    accuracy = accuracy_score(all_labels, all_preds)\n    return accuracy\n\n# Example usage\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Evaluating Overall Accuracy for the first model...\")\noverall_accuracy = evaluate_overall_accuracy(model_before_mitigating, val_loader, device=device)\nprint(f\"Overall Accuracy: {overall_accuracy:.4f}\")","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:08:34.459615Z","iopub.status.busy":"2025-01-04T21:08:34.459337Z","iopub.status.idle":"2025-01-04T21:08:34.599568Z","shell.execute_reply":"2025-01-04T21:08:34.598786Z","shell.execute_reply.started":"2025-01-04T21:08:34.459594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluating Overall Accuracy for the first model...\n","Overall Accuracy: 0.9390\n"]}],"execution_count":36},{"cell_type":"markdown","source":"# Equal Opportunity","metadata":{}},{"cell_type":"code","source":"def calculate_tpr(labels, preds):\n    tp = np.sum((preds == 1) & (labels == 1))\n    fn = np.sum((preds == 0) & (labels == 1))\n    return tp / (tp + fn) if (tp + fn) > 0 else 0.0\n\ndef evaluate_equal_opportunity(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval()\n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(val_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n                group_labels[group].append(labels.cpu().numpy()[i])\n\n    group_tprs = {}\n    for group in group_preds.keys():\n        preds = np.array(group_preds[group])\n        labels = np.array(group_labels[group])\n        group_tprs[group] = calculate_tpr(labels, preds)\n\n    min_tpr = min(group_tprs.values())\n    max_tpr = max(group_tprs.values())\n    tpr_disparity = max_tpr - min_tpr\n\n    return group_tprs, tpr_disparity","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:08:47.451636Z","iopub.status.busy":"2025-01-04T21:08:47.451337Z","iopub.status.idle":"2025-01-04T21:08:47.458463Z","shell.execute_reply":"2025-01-04T21:08:47.457663Z","shell.execute_reply.started":"2025-01-04T21:08:47.451612Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"group_tprs, tpr_disparity = evaluate_equal_opportunity(deep_copy_model, val_loader, group_inds)\nprint(f\"Group TPRs: {group_tprs}\")\nprint(f\"TPR Disparity: {tpr_disparity:.4f}\")","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:08:49.370758Z","iopub.status.busy":"2025-01-04T21:08:49.370475Z","iopub.status.idle":"2025-01-04T21:08:49.538616Z","shell.execute_reply":"2025-01-04T21:08:49.537695Z","shell.execute_reply.started":"2025-01-04T21:08:49.370735Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Group TPRs: {0.0: 0.9013157894736842, 1.0: 0.8986175115207373, 2.0: 0.898989898989899}\n","TPR Disparity: 0.0027\n"]}],"execution_count":39},{"cell_type":"markdown","source":"# Equal Odds","metadata":{}},{"cell_type":"code","source":"def calculate_fpr(labels, preds):\n    fp = np.sum((preds == 1) & (labels == 0))\n    tn = np.sum((preds == 0) & (labels == 0))\n    return fp / (fp + tn) if (fp + tn) > 0 else 0.0\n\ndef evaluate_equalized_odds(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval()\n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(val_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n                group_labels[group].append(labels.cpu().numpy()[i])\n\n    group_tprs, group_fprs = {}, {}\n    for group in group_preds.keys():\n        preds = np.array(group_preds[group])\n        labels = np.array(group_labels[group])\n        group_tprs[group] = calculate_tpr(labels, preds)\n        group_fprs[group] = calculate_fpr(labels, preds)\n\n    tpr_disparity = max(group_tprs.values()) - min(group_tprs.values())\n    fpr_disparity = max(group_fprs.values()) - min(group_fprs.values())\n\n    return group_tprs, group_fprs, tpr_disparity, fpr_disparity","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:08:51.943110Z","iopub.status.busy":"2025-01-04T21:08:51.942808Z","iopub.status.idle":"2025-01-04T21:08:51.950520Z","shell.execute_reply":"2025-01-04T21:08:51.949566Z","shell.execute_reply.started":"2025-01-04T21:08:51.943088Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"code","source":"group_tprs, group_fprs, tpr_disparity, fpr_disparity = evaluate_equalized_odds(deep_copy_model, val_loader, group_inds)\nprint(f\"Group TPRs: {group_tprs}\")\nprint(f\"Group FPRs: {group_fprs}\")\nprint(f\"TPR Disparity: {tpr_disparity:.4f}\")\nprint(f\"FPR Disparity: {fpr_disparity:.4f}\")","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:08:54.083996Z","iopub.status.busy":"2025-01-04T21:08:54.083677Z","iopub.status.idle":"2025-01-04T21:08:54.258662Z","shell.execute_reply":"2025-01-04T21:08:54.257856Z","shell.execute_reply.started":"2025-01-04T21:08:54.083969Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Group TPRs: {0.0: 0.9013157894736842, 1.0: 0.8986175115207373, 2.0: 0.898989898989899}\n","Group FPRs: {0.0: 0.03773584905660377, 1.0: 0.018656716417910446, 2.0: 0.03816793893129771}\n","TPR Disparity: 0.0027\n","FPR Disparity: 0.0195\n"]}],"execution_count":41},{"cell_type":"markdown","source":"# Demographic Parity","metadata":{}},{"cell_type":"code","source":"def calculate_ppr(preds):\n    return np.mean(preds)\n\n\ndef evaluate_demographic_parity(model, val_loader, group_inds, device=\"cuda\"):\n    \"\"\"\n    Evaluate Demographic Parity.\n    Ensures PPR is correctly normalized as probabilities.\n    \"\"\"\n    model.eval()\n    group_preds = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(val_loader):\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            # Get the group indices for the current batch\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            # Assign predictions to the corresponding group\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n\n    group_pprs = {}\n    for group in group_preds.keys():\n        # Flatten the predictions list for each group and normalize\n        preds = np.array(group_preds[group]).flatten()\n        positive_preds = (preds == 1).sum()  # Count positive predictions\n        total_preds = len(preds)  # Total number of predictions\n        group_pprs[group] = positive_preds / total_preds if total_preds > 0 else 0.0\n\n    # Calculate the disparity in PPRs across groups\n    min_ppr = min(group_pprs.values())\n    max_ppr = max(group_pprs.values())\n    ppr_disparity = max_ppr - min_ppr\n\n    return group_pprs, ppr_disparity","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:08:58.602359Z","iopub.status.busy":"2025-01-04T21:08:58.602054Z","iopub.status.idle":"2025-01-04T21:08:58.608674Z","shell.execute_reply":"2025-01-04T21:08:58.607796Z","shell.execute_reply.started":"2025-01-04T21:08:58.602334Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"group_pprs, ppr_disparity = evaluate_demographic_parity(deep_copy_model, val_loader, group_inds)\nprint(f\"Group PPRs: {group_pprs}\")\nprint(f\"PPR Disparity: {ppr_disparity:.4f}\")","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:09:00.526662Z","iopub.status.busy":"2025-01-04T21:09:00.526359Z","iopub.status.idle":"2025-01-04T21:09:00.673358Z","shell.execute_reply":"2025-01-04T21:09:00.672386Z","shell.execute_reply.started":"2025-01-04T21:09:00.526639Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Group PPRs: {0.0: 0.3983516483516483, 1.0: 0.41237113402061853, 2.0: 0.40869565217391307}\n","PPR Disparity: 0.0140\n"]}],"execution_count":43},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\nfrom tqdm import tqdm\n\ndef calculate_fnr_fpr(model, val_loader, group_inds, device=\"cuda\"):\n    \"\"\"\n    Calculate False Negative Rate (FNR) and False Positive Rate (FPR) for each group.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n    group_metrics = {g: {\"FN\": 0, \"FP\": 0, \"TP\": 0, \"TN\": 0} for g in set(group_inds)}  # Metrics for each group\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader, desc=\"Calculating FNR and FPR\")):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            labels = labels.cpu().numpy()\n\n            # Get the groups for the current batch\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                if group not in group_metrics:\n                    continue  # Skip if group is not defined\n                \n                # Update confusion matrix components\n                if labels[i] == 1 and preds[i] == 0:  # False Negative\n                    group_metrics[group][\"FN\"] += 1\n                elif labels[i] == 0 and preds[i] == 1:  # False Positive\n                    group_metrics[group][\"FP\"] += 1\n                elif labels[i] == 1 and preds[i] == 1:  # True Positive\n                    group_metrics[group][\"TP\"] += 1\n                elif labels[i] == 0 and preds[i] == 0:  # True Negative\n                    group_metrics[group][\"TN\"] += 1\n\n    # Calculate FNR and FPR for each group\n    group_fnr_fpr = {}\n    for group, metrics in group_metrics.items():\n        fn = metrics[\"FN\"]\n        fp = metrics[\"FP\"]\n        tp = metrics[\"TP\"]\n        tn = metrics[\"TN\"]\n\n        actual_positives = tp + fn\n        actual_negatives = tn + fp\n\n        fnr = fn / (actual_positives + 1e-8) if actual_positives > 0 else 0.0\n        fpr = fp / (actual_negatives + 1e-8) if actual_negatives > 0 else 0.0\n\n        group_fnr_fpr[group] = {\"FNR\": fnr, \"FPR\": fpr}\n\n    # Print FNR and FPR for each group\n    print(\"\\nGroup FNR and FPR:\")\n    for group, metrics in group_fnr_fpr.items():\n        print(f\"Group {group}: FNR = {metrics['FNR']:.4f}, FPR = {metrics['FPR']:.4f}\")\n\n    # Calculate and print disparities\n    fnr_values = [metrics[\"FNR\"] for metrics in group_fnr_fpr.values()]\n    fpr_values = [metrics[\"FPR\"] for metrics in group_fnr_fpr.values()]\n    fnr_disparity = max(fnr_values) - min(fnr_values)\n    fpr_disparity = max(fpr_values) - min(fpr_values)\n\n    print(f\"\\nFNR Disparity (Max - Min): {fnr_disparity:.4f}\")\n    print(f\"FPR Disparity (Max - Min): {fpr_disparity:.4f}\")\n\n    return group_fnr_fpr, fnr_disparity, fpr_disparity\n\n\n# Example usage\ngroup_fnr_fpr, fnr_disparity, fpr_disparity = calculate_fnr_fpr(model_before_mitigating, val_loader, group_inds)","metadata":{"execution":{"iopub.execute_input":"2025-01-04T21:09:03.330777Z","iopub.status.busy":"2025-01-04T21:09:03.330463Z","iopub.status.idle":"2025-01-04T21:09:03.487764Z","shell.execute_reply":"2025-01-04T21:09:03.486866Z","shell.execute_reply.started":"2025-01-04T21:09:03.330745Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Calculating FNR and FPR: 100%|██████████| 46/46 [00:00<00:00, 323.07it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Group FNR and FPR:\n","Group 0.0: FNR = 0.0987, FPR = 0.0377\n","Group 1.0: FNR = 0.1014, FPR = 0.0187\n","Group 2.0: FNR = 0.1010, FPR = 0.0382\n","\n","FNR Disparity (Max - Min): 0.0027\n","FPR Disparity (Max - Min): 0.0195\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":44},{"cell_type":"markdown","source":"# Machine Unlearning","metadata":{}},{"cell_type":"code","source":"harmful_indices = debiased_inds\n\ndef remove_influence(model, dataloader, harmful_indices, factor, device=\"cuda\"):\n    model.eval()\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    for inputs, labels in harmful_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(model.parameters(), grads):\n                param -= grad * factor\n\n    return model\n\nresults ={'factor':[], 'model':[], 'min':[], 'max':[], 'gap':[]}\nfactors = np.linspace(0.0001, 0.01, 20)\n\nfor factor in factors:\n    newdeepmodel = copy.deepcopy(deep_copy_model)\n    m = remove_influence(newdeepmodel, train_loader, harmful_indices, factor, device=\"cuda\")\n    wga, group_accs = evaluate_worst_group_accuracy(m, val_loader, group_inds, device=\"cuda\")\n    current_gap = (max(group_accs.values()) - wga)\n    results['model'].append(m)\n    results['min'].append(wga)\n    results['max'].append(max(group_accs.values()))\n    results['gap'].append(current_gap)\n    results['factor'].append(factor)   ","metadata":{"execution":{"iopub.execute_input":"2025-01-04T20:43:15.730961Z","iopub.status.busy":"2025-01-04T20:43:15.730681Z","iopub.status.idle":"2025-01-04T20:45:20.139691Z","shell.execute_reply":"2025-01-04T20:45:20.138847Z","shell.execute_reply.started":"2025-01-04T20:43:15.730940Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 697.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7047\n","Group 1.0 Accuracy: 0.6680\n","Group 2.0 Accuracy: 0.6957\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 699.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7033\n","Group 1.0 Accuracy: 0.6742\n","Group 2.0 Accuracy: 0.6913\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 694.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7005\n","Group 1.0 Accuracy: 0.6784\n","Group 2.0 Accuracy: 0.6913\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 680.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6964\n","Group 1.0 Accuracy: 0.6784\n","Group 2.0 Accuracy: 0.6870\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 695.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7019\n","Group 1.0 Accuracy: 0.6742\n","Group 2.0 Accuracy: 0.6826\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 703.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7033\n","Group 1.0 Accuracy: 0.6742\n","Group 2.0 Accuracy: 0.6826\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 694.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7033\n","Group 1.0 Accuracy: 0.6722\n","Group 2.0 Accuracy: 0.6783\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 681.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6992\n","Group 1.0 Accuracy: 0.6680\n","Group 2.0 Accuracy: 0.6826\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 681.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6978\n","Group 1.0 Accuracy: 0.6742\n","Group 2.0 Accuracy: 0.6783\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 681.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7019\n","Group 1.0 Accuracy: 0.6680\n","Group 2.0 Accuracy: 0.6739\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 687.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7033\n","Group 1.0 Accuracy: 0.6660\n","Group 2.0 Accuracy: 0.6696\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 691.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7019\n","Group 1.0 Accuracy: 0.6619\n","Group 2.0 Accuracy: 0.6609\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 696.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6992\n","Group 1.0 Accuracy: 0.6680\n","Group 2.0 Accuracy: 0.6652\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 701.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6964\n","Group 1.0 Accuracy: 0.6557\n","Group 2.0 Accuracy: 0.6652\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 673.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6992\n","Group 1.0 Accuracy: 0.6557\n","Group 2.0 Accuracy: 0.6609\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 698.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6964\n","Group 1.0 Accuracy: 0.6557\n","Group 2.0 Accuracy: 0.6609\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 703.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6964\n","Group 1.0 Accuracy: 0.6536\n","Group 2.0 Accuracy: 0.6609\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 701.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6937\n","Group 1.0 Accuracy: 0.6495\n","Group 2.0 Accuracy: 0.6565\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 705.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.6978\n","Group 1.0 Accuracy: 0.6495\n","Group 2.0 Accuracy: 0.6565\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 46/46 [00:00<00:00, 706.27it/s]"]},{"name":"stdout","output_type":"stream","text":["Group 0.0 Accuracy: 0.7005\n","Group 1.0 Accuracy: 0.6598\n","Group 2.0 Accuracy: 0.6609\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(results).sort_values('factor')\ndf","metadata":{"execution":{"iopub.execute_input":"2025-01-04T20:45:20.140960Z","iopub.status.busy":"2025-01-04T20:45:20.140693Z","iopub.status.idle":"2025-01-04T20:45:20.154346Z","shell.execute_reply":"2025-01-04T20:45:20.153542Z","shell.execute_reply.started":"2025-01-04T20:45:20.140935Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>factor</th>\n","      <th>model</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>gap</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000100</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.668041</td>\n","      <td>0.704670</td>\n","      <td>0.036629</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000621</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.674227</td>\n","      <td>0.703297</td>\n","      <td>0.029070</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.001142</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.678351</td>\n","      <td>0.700549</td>\n","      <td>0.022199</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.001663</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.678351</td>\n","      <td>0.696429</td>\n","      <td>0.018078</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.002184</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.674227</td>\n","      <td>0.701923</td>\n","      <td>0.027696</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.002705</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.674227</td>\n","      <td>0.703297</td>\n","      <td>0.029070</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.003226</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.672165</td>\n","      <td>0.703297</td>\n","      <td>0.031132</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.003747</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.668041</td>\n","      <td>0.699176</td>\n","      <td>0.031135</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.004268</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.674227</td>\n","      <td>0.697802</td>\n","      <td>0.023575</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.004789</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.668041</td>\n","      <td>0.701923</td>\n","      <td>0.033882</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.005311</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.665979</td>\n","      <td>0.703297</td>\n","      <td>0.037317</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.005832</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.660870</td>\n","      <td>0.701923</td>\n","      <td>0.041054</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.006353</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.665217</td>\n","      <td>0.699176</td>\n","      <td>0.033958</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.006874</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.655670</td>\n","      <td>0.696429</td>\n","      <td>0.040758</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.007395</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.655670</td>\n","      <td>0.699176</td>\n","      <td>0.043506</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.007916</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.655670</td>\n","      <td>0.696429</td>\n","      <td>0.040758</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.008437</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.653608</td>\n","      <td>0.696429</td>\n","      <td>0.042820</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.008958</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.649485</td>\n","      <td>0.693681</td>\n","      <td>0.044197</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.009479</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.649485</td>\n","      <td>0.697802</td>\n","      <td>0.048318</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.010000</td>\n","      <td>COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...</td>\n","      <td>0.659794</td>\n","      <td>0.700549</td>\n","      <td>0.040756</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      factor                                              model       min  \\\n","0   0.000100  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.668041   \n","1   0.000621  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n","2   0.001142  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.678351   \n","3   0.001663  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.678351   \n","4   0.002184  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n","5   0.002705  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n","6   0.003226  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.672165   \n","7   0.003747  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.668041   \n","8   0.004268  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.674227   \n","9   0.004789  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.668041   \n","10  0.005311  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.665979   \n","11  0.005832  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.660870   \n","12  0.006353  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.665217   \n","13  0.006874  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.655670   \n","14  0.007395  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.655670   \n","15  0.007916  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.655670   \n","16  0.008437  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.653608   \n","17  0.008958  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.649485   \n","18  0.009479  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.649485   \n","19  0.010000  COMPASModel(\\n  (fc): Sequential(\\n    (0): Li...  0.659794   \n","\n","         max       gap  \n","0   0.704670  0.036629  \n","1   0.703297  0.029070  \n","2   0.700549  0.022199  \n","3   0.696429  0.018078  \n","4   0.701923  0.027696  \n","5   0.703297  0.029070  \n","6   0.703297  0.031132  \n","7   0.699176  0.031135  \n","8   0.697802  0.023575  \n","9   0.701923  0.033882  \n","10  0.703297  0.037317  \n","11  0.701923  0.041054  \n","12  0.699176  0.033958  \n","13  0.696429  0.040758  \n","14  0.699176  0.043506  \n","15  0.696429  0.040758  \n","16  0.696429  0.042820  \n","17  0.693681  0.044197  \n","18  0.697802  0.048318  \n","19  0.700549  0.040756  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"execution_count":23},{"cell_type":"markdown","source":"Now, it's time to investigate what are the best approaches to machine unlearning and how can we formulate that.","metadata":{}},{"cell_type":"markdown","source":"What are the other approaches to machine unlearning?","metadata":{}},{"cell_type":"markdown","source":"Other Fairness notations might come in handy!","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
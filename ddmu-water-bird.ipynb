{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":4505237,"sourceType":"datasetVersion","datasetId":2633528}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"pip install traker","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trak import TRAKer\n\ndef get_trak_matrix(\n    train_dl, val_dl, model, ckpts, train_set_size, val_set_size, **kwargs\n):\n    if kwargs is None or kwargs.get(\"task\") is None:\n        task = \"image_classification\"\n    else:\n        task = kwargs.pop(\"task\")\n\n    traker = TRAKer(model=model, task=task, train_set_size=train_set_size, **kwargs)\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.load_checkpoint(checkpoint, model_id=model_id)\n        for batch in train_dl:\n            batch = [x.cuda() for x in batch]\n            # batch should be a tuple/list of inputs and labels\n            traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n\n    traker.finalize_features()\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.start_scoring_checkpoint(\n            exp_name=\"test\",\n            checkpoint=checkpoint,\n            model_id=model_id,\n            num_targets=val_set_size,\n        )\n    for batch in val_dl:\n        batch = [x.cuda() for x in batch]\n        traker.score(batch=batch, num_samples=batch[0].shape[0])\n\n    scores = traker.finalize_scores(exp_name=\"test\")\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:56:05.084653Z","iopub.execute_input":"2025-01-12T18:56:05.085012Z","iopub.status.idle":"2025-01-12T18:56:07.906280Z","shell.execute_reply.started":"2025-01-12T18:56:05.084980Z","shell.execute_reply":"2025-01-12T18:56:07.905590Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.nn import functional as F\n\nclass DDA:\n    def __init__(\n        self,\n        model,\n        checkpoints,\n        train_dataloader,\n        val_dataloader,\n        group_indices,\n        train_set_size=None,\n        val_set_size=None,\n        trak_scores=None,\n        trak_kwargs=None,\n        device=\"cuda\",\n    ) -> None:\n        \n        self.model = model\n        self.checkpoints = checkpoints\n        self.dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n        self.group_indices = group_indices\n        self.device = device\n\n        if trak_scores is not None:\n            self.trak_scores = trak_scores\n        else:\n            try:\n                self.train_set_size = len(train_dataloader.dataset)\n                self.val_set_size = len(val_dataloader.dataset)\n            except AttributeError as e:\n                print(\n                    f\"No dataset attribute found in train_dataloader or val_dataloader. {e}\"\n                )\n                if train_set_size is None or val_set_size is None:\n                    raise ValueError(\n                        \"train_set_size and val_set_size must be specified if \"\n                        \"train_dataloader and val_dataloader do not have a \"\n                        \"dataset attribute.\"\n                    ) from e\n                self.train_set_size = train_set_size\n                self.val_set_size = val_set_size\n\n            # Step 1: compute TRAK scores\n            if trak_kwargs is not None:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                    **trak_kwargs,\n                )\n            else:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                )\n\n            self.trak_scores = trak_scores\n\n    def get_group_losses(self, model, val_dl, group_indices) -> list:\n        losses = []\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in val_dl:\n                outputs = model(inputs.to(self.device))\n                loss = F.cross_entropy(\n                    outputs, labels.to(self.device), reduction=\"none\"\n                )\n                losses.append(loss)\n        losses = torch.cat(losses)\n\n        n_groups = len(set(group_indices))\n        group_losses = [losses[group_indices == i].mean() for i in range(n_groups)]\n        return group_losses\n\n    def compute_group_alignment_scores(self, trak_scores, group_indices, group_losses):\n        n_groups = len(set(group_indices))\n        S = np.array(trak_scores)\n        g = [\n            group_losses[i].cpu().numpy() * S[:, np.array(group_indices) == i].mean(axis=1)\n            for i in range(n_groups)\n        ]\n        g = np.stack(g)\n        group_alignment_scores = g.mean(axis=0)\n        return group_alignment_scores\n\n    def get_debiased_train_indices(\n        self, group_alignment_scores, use_heuristic=True, num_to_discard=None\n    ):\n        if use_heuristic:\n            return [i for i, score in enumerate(group_alignment_scores) if score >= 0]\n\n        if num_to_discard is None:\n            raise ValueError(\"num_to_discard must be specified if not using heuristic.\")\n\n        sorted_indices = sorted(\n            range(len(group_alignment_scores)),\n            key=lambda i: group_alignment_scores[i],\n        )\n        return sorted_indices[num_to_discard:]\n\n    def debias(self, use_heuristic=True, num_to_discard=None):\n        group_losses = self.get_group_losses(\n            model=self.model,\n            val_dl=self.dataloaders[\"val\"],\n            group_indices=self.group_indices,\n        )\n\n        group_alignment_scores = self.compute_group_alignment_scores(\n            self.trak_scores, self.group_indices, group_losses\n        )\n        \n        debiased_train_inds = self.get_debiased_train_indices(\n            group_alignment_scores,\n            use_heuristic=use_heuristic,\n            num_to_discard=num_to_discard,\n        )\n\n        return debiased_train_inds\n","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:56:11.002197Z","iopub.execute_input":"2025-01-12T18:56:11.002536Z","iopub.status.idle":"2025-01-12T18:56:11.014855Z","shell.execute_reply.started":"2025-01-12T18:56:11.002506Z","shell.execute_reply":"2025-01-12T18:56:11.013987Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:56:11.770829Z","iopub.execute_input":"2025-01-12T18:56:11.771067Z","iopub.status.idle":"2025-01-12T18:56:11.774368Z","shell.execute_reply.started":"2025-01-12T18:56:11.771047Z","shell.execute_reply":"2025-01-12T18:56:11.773644Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Water Bird","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nwaterbirds_images_path = \"/kaggle/input/waterbird/waterbird\"\nmetadata_path = \"/kaggle/input/waterbird/waterbird/metadata.csv\"\n\ndef get_dataloader(batch_size=32, num_workers=4, split=\"train\", shuffle=False, augment=True):\n    if augment:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.RandomHorizontalFlip(),\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n    else:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n\n    metadata = pd.read_csv(metadata_path)\n    split_mapping = {\"train\": 0, \"val\": 1, \"test\": 2}\n    split_label = split_mapping[split]\n    selected_metadata = metadata[metadata[\"split\"] == split_label]\n\n    class WaterbirdsDataset(Dataset):\n        def __init__(self, metadata, img_dir, transform=None):\n            self.metadata = metadata\n            self.img_dir = img_dir\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.metadata)\n\n        def __getitem__(self, idx):\n            row = self.metadata.iloc[idx]\n            img_path = os.path.join(self.img_dir, row[\"img_filename\"])\n            image = Image.open(img_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            label = torch.tensor(row[\"y\"], dtype=torch.long)\n            return image, label\n\n    dataset = WaterbirdsDataset(metadata=selected_metadata, img_dir=waterbirds_images_path, transform=transforms_pipeline)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n\n    return loader, dataset\n\nfrom torchvision.models import resnet18, ResNet18_Weights\nmodel = resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel.fc = nn.Linear(model.fc.in_features, 2)\nmodel = model.cuda()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(\n    model.parameters(), lr=1e-4, weight_decay=1e-4\n)\n\ntrain_loader, train_dataset = get_dataloader(batch_size=32, split=\"train\", shuffle=True)\nval_loader, val_dataset = get_dataloader(batch_size=32, split=\"val\", shuffle=False, augment=False)\n\nprint(f\"Total training images: {len(train_dataset)}\")\nprint(f\"Total validation images: {len(val_dataset)}\")\n\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    model.train()\n    epoch_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=\"Training\"):\n        images = images.cuda()\n        labels = labels.cuda()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        epoch_loss += loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Training Loss: {avg_loss:.4f}\")\n\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n            images = images.cuda()\n            labels = labels.cuda()\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n\nprint(\"Training and evaluation completed.\")","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:56:13.447331Z","iopub.execute_input":"2025-01-12T18:56:13.447598Z","iopub.status.idle":"2025-01-12T18:57:10.293379Z","shell.execute_reply.started":"2025-01-12T18:56:13.447577Z","shell.execute_reply":"2025-01-12T18:57:10.292381Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 74.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Total training images: 4795\nTotal validation images: 1199\n\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:14<00:00, 10.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2211\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:03<00:00, 10.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 85.99%\n\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:07<00:00, 19.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0717\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:01<00:00, 22.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 84.99%\n\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:07<00:00, 20.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0445\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:01<00:00, 19.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 80.48%\n\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:07<00:00, 21.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0364\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:01<00:00, 23.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 81.65%\n\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:07<00:00, 20.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0308\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:01<00:00, 23.10it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 82.57%\nTraining and evaluation completed.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import copy\n\nmodel_before_mitigating = copy.deepcopy(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:59:22.621086Z","iopub.execute_input":"2025-01-12T18:59:22.621486Z","iopub.status.idle":"2025-01-12T18:59:22.641384Z","shell.execute_reply.started":"2025-01-12T18:59:22.621451Z","shell.execute_reply":"2025-01-12T18:59:22.640758Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport numpy as np\n\ndef evaluate_worst_group_accuracy(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval() \n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating WGA\")):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n                group_labels[group].append(labels.cpu().numpy()[i]) \n\n    group_accuracies = {}\n    for group in group_preds.keys():\n        if len(group_preds[group]) == 0 or len(group_labels[group]) == 0:\n            group_accuracies[group] = 0.0\n            continue\n\n        preds = np.array(group_preds[group])\n        truths = np.array(group_labels[group])\n        group_accuracies[group] = accuracy_score(truths, preds)\n\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n\n    worst_group_accuracy = min(group_accuracies.values())\n    return worst_group_accuracy, group_accuracies","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:59:26.583556Z","iopub.execute_input":"2025-01-12T18:59:26.583862Z","iopub.status.idle":"2025-01-12T18:59:27.061597Z","shell.execute_reply.started":"2025-01-12T18:59:26.583838Z","shell.execute_reply":"2025-01-12T18:59:27.060689Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\nmetadata = pd.read_csv(metadata_path)\nprint(metadata.size)\n\ndef define_subgroups(row):\n    if row[\"place\"] == 0:\n        return \"land-background\"\n    elif row[\"place\"] == 1:\n        return \"water-background\"\n\nmetadata[\"subgroup\"] = metadata.apply(define_subgroups, axis=1)\n\nsubgroup_mapping = {name: i for i, name in enumerate(metadata[\"subgroup\"].unique())}\nmetadata[\"group_index\"] = metadata[\"subgroup\"].map(subgroup_mapping)\n\nprint(\"Subgroup Distribution:\")\nprint(metadata[\"subgroup\"].value_counts())\n\nval_metadata = metadata[metadata[\"split\"] == 1]  \ngroup_inds = val_metadata['subgroup'].map(subgroup_mapping).values\ngroup_labels = val_metadata[\"group_index\"].values\nprint(f\"Sample Group Indices (Validation): {group_labels[:10]}\")\n\n# val_indices = val_loader.dataset.indices  \n# group_labels = attributes.loc[val_indices, \"group_index\"].values\n# group_inds = list(group_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:59:27.581563Z","iopub.execute_input":"2025-01-12T18:59:27.582228Z","iopub.status.idle":"2025-01-12T18:59:27.700483Z","shell.execute_reply.started":"2025-01-12T18:59:27.582196Z","shell.execute_reply":"2025-01-12T18:59:27.699590Z"}},"outputs":[{"name":"stdout","text":"70728\nSubgroup Distribution:\nsubgroup\nland-background     7051\nwater-background    4737\nName: count, dtype: int64\nSample Group Indices (Validation): [0 1 0 0 1 0 1 1 0 1]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\n\ndef evaluate_group_accuracies(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_preds = {g: [] for g in set(group_labels)}\n    group_truths = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Group Accuracies\")):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_preds[group].append(preds[j])\n                group_truths[group].append(labels.cpu().numpy()[j])\n\n    group_accuracies = {}\n    for group in group_preds:\n        if len(group_preds[group]) == 0:\n            group_accuracies[group] = 0.0\n        else:\n            preds = np.array(group_preds[group])\n            truths = np.array(group_truths[group])\n            group_accuracies[group] = accuracy_score(truths, preds)\n\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n    \n    return group_accuracies\n\ndef evaluate_demographic_parity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_pprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, _) in enumerate(tqdm(val_loader, desc=\"Evaluating Demographic Parity\")):\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(preds)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_pprs[group].append(preds[j])\n\n    ppr_disparities = {}\n    for group in group_pprs:\n        group_positive_rate = np.mean(group_pprs[group])\n        ppr_disparities[group] = group_positive_rate\n\n    for group, ppr in ppr_disparities.items():\n        print(f\"Group {group} PPR: {ppr:.4f}\")\n    \n    return ppr_disparities\n\ndef evaluate_equal_opportunity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equal Opportunity\")):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                actual_positive = labels[j].cpu().numpy() == 1\n                group_tprs[group].append(tp / (actual_positive + 1e-8))\n\n    tpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n\n    for group, tpr in tpr_disparities.items():\n        print(f\"Group {group} TPR: {tpr:.4f}\")\n    \n    return tpr_disparities\n\ndef evaluate_equalized_odds(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n    group_fprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equalized Odds\")):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                fp = (preds[j] == 1 and labels[j].cpu().numpy() == 0)\n                actual_positive = labels[j].cpu().numpy() == 1\n                actual_negative = labels[j].cpu().numpy() == 0\n\n                group_tprs[group].append(tp / (actual_positive + 1e-8))\n                group_fprs[group].append(fp / (actual_negative + 1e-8))\n\n    tpr_disparities = {}\n    fpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n        fpr_disparities[group] = np.mean(group_fprs[group])\n\n    for group in group_tprs:\n        print(f\"Group {group} TPR: {tpr_disparities[group]:.4f}, FPR: {fpr_disparities[group]:.4f}\")\n    \n    return tpr_disparities, fpr_disparities","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:59:47.201658Z","iopub.execute_input":"2025-01-12T18:59:47.201981Z","iopub.status.idle":"2025-01-12T18:59:47.218073Z","shell.execute_reply.started":"2025-01-12T18:59:47.201951Z","shell.execute_reply":"2025-01-12T18:59:47.217199Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"wga, group_accuracies = evaluate_worst_group_accuracy(model_before_mitigating, val_loader, group_labels)\ndp_rates = evaluate_demographic_parity(model_before_mitigating, val_loader, group_labels)\neo_tprs = evaluate_equal_opportunity(model_before_mitigating, val_loader, group_labels)\ntpr_disparities, fpr_disparities = evaluate_equalized_odds(model_before_mitigating, val_loader, group_labels)","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:59:51.548808Z","iopub.execute_input":"2025-01-12T18:59:51.549096Z","iopub.status.idle":"2025-01-12T18:59:58.655324Z","shell.execute_reply.started":"2025-01-12T18:59:51.549074Z","shell.execute_reply":"2025-01-12T18:59:58.654273Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 20.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.7629\nGroup 1 Accuracy: 0.8883\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Demographic Parity: 100%|██████████| 38/38 [00:01<00:00, 22.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 PPR: 0.4190\nGroup 1 PPR: 0.1300\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Equal Opportunity: 100%|██████████| 38/38 [00:01<00:00, 21.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 TPR: 0.2020\nGroup 1 TPR: 0.1200\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Equalized Odds: 100%|██████████| 38/38 [00:01<00:00, 21.89it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0 TPR: 0.2020, FPR: 0.2170\nGroup 1 TPR: 0.1200, FPR: 0.0100\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Debiasing with D3M","metadata":{}},{"cell_type":"code","source":"print('YOYO')\nckpts = [model_before_mitigating.state_dict()]\ndda = DDA(model_before_mitigating, ckpts, train_loader, val_loader, group_inds)","metadata":{"execution":{"iopub.status.busy":"2025-01-12T19:02:12.083041Z","iopub.execute_input":"2025-01-12T19:02:12.083507Z","iopub.status.idle":"2025-01-12T19:06:48.005223Z","shell.execute_reply.started":"2025-01-12T19:02:12.083472Z","shell.execute_reply":"2025-01-12T19:06:48.004233Z"},"trusted":true},"outputs":[{"name":"stdout","text":"YOYO\n","output_type":"stream"},{"name":"stderr","text":"Finalizing features for all model IDs..: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\nFinalizing scores for all model IDs..: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# group_alignment_scores = dda.compute_group_alignment_scores(\n#     dda.trak_scores, dda.group_indices, dda.get_group_losses(\n#         dda.model, dda.dataloaders[\"val\"], dda.group_indices\n#     )\n# )\n# print(\"Group Alignment Scores Stats:\")\n# print(f\"Mean: {np.mean(group_alignment_scores):.4f}\")\n# print(f\"Min: {np.min(group_alignment_scores):.4f}\")\n# print(f\"Max: {np.max(group_alignment_scores):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T17:04:44.292631Z","iopub.execute_input":"2025-01-12T17:04:44.292942Z","iopub.status.idle":"2025-01-12T17:04:46.394713Z","shell.execute_reply.started":"2025-01-12T17:04:44.292919Z","shell.execute_reply":"2025-01-12T17:04:46.393672Z"}},"outputs":[{"name":"stdout","text":"Group Alignment Scores Stats:\nMean: -0.0001\nMin: -0.1323\nMax: 0.0777\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"debiased_inds = dda.debias(use_heuristic=False, num_to_discard=1500)\n# debiased_inds = dda.debias(use_heuristic=True)\nlen(debiased_inds)","metadata":{"execution":{"iopub.status.busy":"2025-01-12T19:13:24.671242Z","iopub.execute_input":"2025-01-12T19:13:24.671585Z","iopub.status.idle":"2025-01-12T19:13:26.492083Z","shell.execute_reply.started":"2025-01-12T19:13:24.671558Z","shell.execute_reply":"2025-01-12T19:13:26.491055Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"3295"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import copy\n\ndeep_copy_model = copy.deepcopy(model_before_mitigating)","metadata":{"execution":{"iopub.status.busy":"2025-01-12T19:13:28.449299Z","iopub.execute_input":"2025-01-12T19:13:28.449636Z","iopub.status.idle":"2025-01-12T19:13:28.470345Z","shell.execute_reply.started":"2025-01-12T19:13:28.449607Z","shell.execute_reply":"2025-01-12T19:13:28.469487Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Machine Unlearning","metadata":{}},{"cell_type":"code","source":"all_train_indices = np.arange(len(train_loader.dataset))\n\nharmful_indices = np.setdiff1d(all_train_indices, debiased_inds)\n\nprint(f\"Total training samples: {len(all_train_indices)}\")\nprint(f\"Debiased indices count: {len(debiased_inds)}\")\nprint(f\"Harmful indices count: {len(harmful_indices)}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-12T19:13:33.782576Z","iopub.execute_input":"2025-01-12T19:13:33.782880Z","iopub.status.idle":"2025-01-12T19:13:33.789447Z","shell.execute_reply.started":"2025-01-12T19:13:33.782856Z","shell.execute_reply":"2025-01-12T19:13:33.788750Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total training samples: 4795\nDebiased indices count: 3295\nHarmful indices count: 1500\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def remove_influence(model, dataloader, harmful_indices, factor, device=\"cuda\"):\n    model.eval()\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    for inputs, labels in harmful_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(model.parameters(), grads):\n                param -= grad * factor\n\n    return model\n\nresults ={'factor':[], 'model':[], 'min':[], 'max':[], 'gap':[]}\nfactors = np.linspace(0.0001, 0.001, 10)\n\nfor factor in factors:\n    newdeepmodel = copy.deepcopy(deep_copy_model)\n    m = remove_influence(newdeepmodel, train_loader, harmful_indices, factor, device=\"cuda\")\n    wga, group_accs = evaluate_worst_group_accuracy(m, val_loader, group_inds, device=\"cuda\")\n    current_gap = (max(group_accs.values()) - wga)\n    results['model'].append(m)\n    results['min'].append(wga)\n    results['max'].append(max(group_accs.values()))\n    results['gap'].append(current_gap)\n    results['factor'].append(factor)","metadata":{"execution":{"iopub.status.busy":"2025-01-12T19:13:50.292766Z","iopub.execute_input":"2025-01-12T19:13:50.293049Z","iopub.status.idle":"2025-01-12T19:16:59.398086Z","shell.execute_reply.started":"2025-01-12T19:13:50.293027Z","shell.execute_reply":"2025-01-12T19:16:59.397018Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 22.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8481\nGroup 1 Accuracy: 0.8567\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 21.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8648\nGroup 1 Accuracy: 0.8500\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 23.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8314\nGroup 1 Accuracy: 0.8500\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 21.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8414\nGroup 1 Accuracy: 0.8500\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 23.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8347\nGroup 1 Accuracy: 0.8667\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 23.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8614\nGroup 1 Accuracy: 0.8117\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 20.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8431\nGroup 1 Accuracy: 0.7900\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 23.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.8548\nGroup 1 Accuracy: 0.7967\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 23.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.7780\nGroup 1 Accuracy: 0.7783\n","output_type":"stream"},{"name":"stderr","text":"Evaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 24.01it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.7780\nGroup 1 Accuracy: 0.7783\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(results).sort_values('factor')\ndf","metadata":{"execution":{"iopub.status.busy":"2025-01-12T19:18:51.142595Z","iopub.execute_input":"2025-01-12T19:18:51.142984Z","iopub.status.idle":"2025-01-12T19:18:51.171778Z","shell.execute_reply.started":"2025-01-12T19:18:51.142955Z","shell.execute_reply":"2025-01-12T19:18:51.170958Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   factor                                              model       min  \\\n0  0.0001  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.848080   \n1  0.0002  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.850000   \n2  0.0003  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.831386   \n3  0.0004  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.841402   \n4  0.0005  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.834725   \n5  0.0006  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.811667   \n6  0.0007  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.790000   \n7  0.0008  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.796667   \n8  0.0009  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.777963   \n9  0.0010  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.777963   \n\n        max       gap  \n0  0.856667  0.008587  \n1  0.864775  0.014775  \n2  0.850000  0.018614  \n3  0.850000  0.008598  \n4  0.866667  0.031942  \n5  0.861436  0.049769  \n6  0.843072  0.053072  \n7  0.854758  0.058091  \n8  0.778333  0.000370  \n9  0.778333  0.000370  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>factor</th>\n      <th>model</th>\n      <th>min</th>\n      <th>max</th>\n      <th>gap</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0001</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.848080</td>\n      <td>0.856667</td>\n      <td>0.008587</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0002</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.850000</td>\n      <td>0.864775</td>\n      <td>0.014775</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0003</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.831386</td>\n      <td>0.850000</td>\n      <td>0.018614</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0004</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.841402</td>\n      <td>0.850000</td>\n      <td>0.008598</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0005</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.834725</td>\n      <td>0.866667</td>\n      <td>0.031942</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0006</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.811667</td>\n      <td>0.861436</td>\n      <td>0.049769</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0007</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.790000</td>\n      <td>0.843072</td>\n      <td>0.053072</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0008</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.796667</td>\n      <td>0.854758</td>\n      <td>0.058091</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0009</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.777963</td>\n      <td>0.778333</td>\n      <td>0.000370</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0010</td>\n      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n      <td>0.777963</td>\n      <td>0.778333</td>\n      <td>0.000370</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"Now, it's time to investigate what are the best approaches to machine unlearning and how can we formulate that.","metadata":{}},{"cell_type":"markdown","source":"What are the other approaches to machine unlearning?","metadata":{}},{"cell_type":"markdown","source":"# Fair Pruning","metadata":{}},{"cell_type":"code","source":"import torch\nimport copy\n\ndef fair_pruning(model, dataloader, harmful_indices, threshold=0.01, device=\"cuda\"):\n    model.eval()\n    pruned_model = copy.deepcopy(model)\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    parameter_gradients = []\n    for inputs, labels in tqdm(harmful_loader, desc=\"Calculating Gradients\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = pruned_model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, pruned_model.parameters(), retain_graph=True)\n        parameter_gradients.append([grad.clone() for grad in grads])\n\n    with torch.no_grad():\n        for param, grads in zip(pruned_model.parameters(), zip(*parameter_gradients)):\n            mean_grad = torch.mean(torch.stack(grads), dim=0)\n            param[torch.abs(mean_grad) < threshold] = 0.0\n\n    return pruned_model\n\npruned_model = fair_pruning(model_before_mitigating, train_loader, harmful_indices, threshold=0.01)\n\nwga, group_accs = evaluate_worst_group_accuracy(pruned_model, val_loader, group_inds, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Differentially Private Influence Functions for Unlearning","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport copy\n\ndef dp_influence_unlearning(model, dataloader, harmful_indices, epsilon=1.0, delta=1e-5, device=\"cuda\"):\n    model.eval()\n    updated_model = copy.deepcopy(model)\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    sensitivity = 1.0 / len(harmful_loader)\n    noise_scale = sensitivity * np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n\n    for inputs, labels in tqdm(harmful_loader, desc=\"Applying DP Influence Unlearning\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = updated_model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, updated_model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(updated_model.parameters(), grads):\n                noise = torch.normal(mean=0, std=noise_scale, size=grad.shape, device=device)\n                param -= (grad + noise)\n\n    return updated_model\n\ndp_model = dp_influence_unlearning(model_before_mitigating, train_loader, harmful_indices, epsilon=1.0, delta=1e-5)\nwga, group_accs = evaluate_worst_group_accuracy(dp_model, val_loader, group_inds, device=\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T18:24:33.457534Z","iopub.execute_input":"2025-01-12T18:24:33.457889Z","iopub.status.idle":"2025-01-12T18:24:36.691486Z","shell.execute_reply.started":"2025-01-12T18:24:33.457862Z","shell.execute_reply":"2025-01-12T18:24:36.690333Z"}},"outputs":[{"name":"stderr","text":"Applying DP Influence Unlearning: 100%|██████████| 95/95 [00:01<00:00, 71.72it/s]\nEvaluating WGA: 100%|██████████| 38/38 [00:01<00:00, 20.29it/s]","output_type":"stream"},{"name":"stdout","text":"Group 0 Accuracy: 0.7780\nGroup 1 Accuracy: 0.7783\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":4505237,"sourceType":"datasetVersion","datasetId":2633528}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"pip install traker","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trak import TRAKer\n\ndef get_trak_matrix(\n    train_dl, val_dl, model, ckpts, train_set_size, val_set_size, **kwargs\n):\n    if kwargs is None or kwargs.get(\"task\") is None:\n        task = \"image_classification\"\n    else:\n        task = kwargs.pop(\"task\")\n\n    traker = TRAKer(model=model, task=task, train_set_size=train_set_size, **kwargs)\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.load_checkpoint(checkpoint, model_id=model_id)\n        for batch in train_dl:\n            batch = [x.cuda() for x in batch]\n            # batch should be a tuple/list of inputs and labels\n            traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n\n    traker.finalize_features()\n\n    for model_id, checkpoint in enumerate(ckpts):\n        traker.start_scoring_checkpoint(\n            exp_name=\"test\",\n            checkpoint=checkpoint,\n            model_id=model_id,\n            num_targets=val_set_size,\n        )\n    for batch in val_dl:\n        batch = [x.cuda() for x in batch]\n        traker.score(batch=batch, num_samples=batch[0].shape[0])\n\n    scores = traker.finalize_scores(exp_name=\"test\")\n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2025-01-10T23:50:31.514286Z","iopub.execute_input":"2025-01-10T23:50:31.514581Z","iopub.status.idle":"2025-01-10T23:50:36.777520Z","shell.execute_reply.started":"2025-01-10T23:50:31.514544Z","shell.execute_reply":"2025-01-10T23:50:36.776619Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.nn import functional as F\n\nclass DDA:\n    def __init__(\n        self,\n        model,\n        checkpoints,\n        train_dataloader,\n        val_dataloader,\n        group_indices,\n        train_set_size=None,\n        val_set_size=None,\n        trak_scores=None,\n        trak_kwargs=None,\n        device=\"cuda\",\n    ) -> None:\n        \n        self.model = model\n        self.checkpoints = checkpoints\n        self.dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n        self.group_indices = group_indices\n        self.device = device\n\n        if trak_scores is not None:\n            self.trak_scores = trak_scores\n        else:\n            try:\n                self.train_set_size = len(train_dataloader.dataset)\n                self.val_set_size = len(val_dataloader.dataset)\n            except AttributeError as e:\n                print(\n                    f\"No dataset attribute found in train_dataloader or val_dataloader. {e}\"\n                )\n                if train_set_size is None or val_set_size is None:\n                    raise ValueError(\n                        \"train_set_size and val_set_size must be specified if \"\n                        \"train_dataloader and val_dataloader do not have a \"\n                        \"dataset attribute.\"\n                    ) from e\n                self.train_set_size = train_set_size\n                self.val_set_size = val_set_size\n\n            # Step 1: compute TRAK scores\n            if trak_kwargs is not None:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                    **trak_kwargs,\n                )\n            else:\n                trak_scores = get_trak_matrix(\n                    train_dl=self.dataloaders[\"train\"],\n                    val_dl=self.dataloaders[\"val\"],\n                    model=self.model,\n                    ckpts=self.checkpoints,\n                    train_set_size=self.train_set_size,\n                    val_set_size=self.val_set_size,\n                )\n\n            self.trak_scores = trak_scores\n\n    def get_group_losses(self, model, val_dl, group_indices) -> list:\n        losses = []\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in val_dl:\n                outputs = model(inputs.to(self.device))\n                loss = F.cross_entropy(\n                    outputs, labels.to(self.device), reduction=\"none\"\n                )\n                losses.append(loss)\n        losses = torch.cat(losses)\n\n        n_groups = len(set(group_indices))\n        group_losses = [losses[group_indices == i].mean() for i in range(n_groups)]\n        return group_losses\n\n    def compute_group_alignment_scores(self, trak_scores, group_indices, group_losses):\n        n_groups = len(set(group_indices))\n        S = np.array(trak_scores)\n        g = [\n            group_losses[i].cpu().numpy() * S[:, np.array(group_indices) == i].mean(axis=1)\n            for i in range(n_groups)\n        ]\n        g = np.stack(g)\n        group_alignment_scores = g.mean(axis=0)\n        return group_alignment_scores\n\n    def get_debiased_train_indices(\n        self, group_alignment_scores, use_heuristic=True, num_to_discard=None\n    ):\n        if use_heuristic:\n            return [i for i, score in enumerate(group_alignment_scores) if score >= 0]\n\n        if num_to_discard is None:\n            raise ValueError(\"num_to_discard must be specified if not using heuristic.\")\n\n        sorted_indices = sorted(\n            range(len(group_alignment_scores)),\n            key=lambda i: group_alignment_scores[i],\n        )\n        return sorted_indices[num_to_discard:]\n\n    def debias(self, use_heuristic=True, num_to_discard=None):\n        group_losses = self.get_group_losses(\n            model=self.model,\n            val_dl=self.dataloaders[\"val\"],\n            group_indices=self.group_indices,\n        )\n\n        group_alignment_scores = self.compute_group_alignment_scores(\n            self.trak_scores, self.group_indices, group_losses\n        )\n        \n        debiased_train_inds = self.get_debiased_train_indices(\n            group_alignment_scores,\n            use_heuristic=use_heuristic,\n            num_to_discard=num_to_discard,\n        )\n\n        return debiased_train_inds\n","metadata":{"execution":{"iopub.status.busy":"2025-01-10T23:50:36.779035Z","iopub.execute_input":"2025-01-10T23:50:36.779423Z","iopub.status.idle":"2025-01-10T23:50:36.791813Z","shell.execute_reply.started":"2025-01-10T23:50:36.779388Z","shell.execute_reply":"2025-01-10T23:50:36.790908Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"execution":{"iopub.status.busy":"2025-01-10T23:50:44.063451Z","iopub.execute_input":"2025-01-10T23:50:44.063796Z","iopub.status.idle":"2025-01-10T23:50:44.067649Z","shell.execute_reply.started":"2025-01-10T23:50:44.063767Z","shell.execute_reply":"2025-01-10T23:50:44.066768Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Water Bird","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nwaterbirds_images_path = \"/kaggle/input/waterbird/waterbird\"\nmetadata_path = \"/kaggle/input/waterbird/waterbird/metadata.csv\"\n\ndef get_dataloader(batch_size=32, num_workers=4, split=\"train\", shuffle=False, augment=True):\n    if augment:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.RandomHorizontalFlip(),\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n    else:\n        transforms_pipeline = transforms.Compose(\n            [\n                transforms.CenterCrop(178),\n                transforms.Resize(128),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n            ]\n        )\n\n    metadata = pd.read_csv(metadata_path)\n    split_mapping = {\"train\": 0, \"val\": 1, \"test\": 2}\n    split_label = split_mapping[split]\n    selected_metadata = metadata[metadata[\"split\"] == split_label]\n\n    class WaterbirdsDataset(Dataset):\n        def __init__(self, metadata, img_dir, transform=None):\n            self.metadata = metadata\n            self.img_dir = img_dir\n            self.transform = transform\n\n        def __len__(self):\n            return len(self.metadata)\n\n        def __getitem__(self, idx):\n            row = self.metadata.iloc[idx]\n            img_path = os.path.join(self.img_dir, row[\"img_filename\"])\n            image = Image.open(img_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            label = torch.tensor(row[\"y\"], dtype=torch.long)\n            return image, label\n\n    dataset = WaterbirdsDataset(metadata=selected_metadata, img_dir=waterbirds_images_path, transform=transforms_pipeline)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n\n    return loader, dataset\n\nfrom torchvision.models import resnet18, ResNet18_Weights\nmodel = resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel.fc = nn.Linear(model.fc.in_features, 2)\nmodel = model.cuda()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(\n    model.parameters(), lr=1e-4, weight_decay=1e-4\n)\n\ntrain_loader, train_dataset = get_dataloader(batch_size=32, split=\"train\", shuffle=True)\nval_loader, val_dataset = get_dataloader(batch_size=32, split=\"val\", shuffle=False, augment=False)\n\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    model.train()\n    epoch_loss = 0.0\n    for images, labels in tqdm(train_loader, desc=\"Training\"):\n        images = images.cuda()\n        labels = labels.cuda()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        epoch_loss += loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Training Loss: {avg_loss:.4f}\")\n\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n            images = images.cuda()\n            labels = labels.cuda()\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n\nprint(\"Training and evaluation completed.\")","metadata":{"execution":{"iopub.status.busy":"2025-01-10T23:54:52.116156Z","iopub.execute_input":"2025-01-10T23:54:52.116854Z","iopub.status.idle":"2025-01-10T23:55:42.560999Z","shell.execute_reply.started":"2025-01-10T23:54:52.116825Z","shell.execute_reply":"2025-01-10T23:55:42.559971Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:08<00:00, 17.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2058\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:02<00:00, 18.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 80.98%\n\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:08<00:00, 17.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0763\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:02<00:00, 15.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 86.74%\n\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:08<00:00, 18.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0526\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:01<00:00, 20.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 81.57%\n\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:07<00:00, 19.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0304\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:01<00:00, 21.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 82.24%\n\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [00:07<00:00, 19.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.0244\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 38/38 [00:01<00:00, 21.43it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 83.57%\nTraining and evaluation completed.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport numpy as np\n\ndef evaluate_worst_group_accuracy(model, val_loader, group_inds, device=\"cuda\"):\n    model.eval() \n    group_preds = {i: [] for i in set(group_inds)}\n    group_labels = {i: [] for i in set(group_inds)}\n\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating WGA\")):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = batch_idx * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_inds[batch_start:batch_end]\n\n            for i, group in enumerate(batch_groups):\n                group_preds[group].append(preds[i])\n                group_labels[group].append(labels.cpu().numpy()[i]) \n\n    group_accuracies = {}\n    for group in group_preds.keys():\n        if len(group_preds[group]) == 0 or len(group_labels[group]) == 0:\n            group_accuracies[group] = 0.0\n            continue\n\n        preds = np.array(group_preds[group])\n        truths = np.array(group_labels[group])\n        group_accuracies[group] = accuracy_score(truths, preds)\n\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n\n    worst_group_accuracy = min(group_accuracies.values())\n    return worst_group_accuracy, group_accuracies","metadata":{"execution":{"iopub.status.busy":"2025-01-10T23:51:27.796306Z","iopub.execute_input":"2025-01-10T23:51:27.796652Z","iopub.status.idle":"2025-01-10T23:51:28.395106Z","shell.execute_reply.started":"2025-01-10T23:51:27.796629Z","shell.execute_reply":"2025-01-10T23:51:28.394399Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\n\nmetadata = pd.read_csv(metadata_path)\n\n# Define subgroups based on background\ndef define_subgroups(row):\n    if row[\"place\"] == 0:\n        return \"land-background\"\n    elif row[\"place\"] == 1:\n        return \"water-background\"\n\nmetadata[\"subgroup\"] = metadata.apply(define_subgroups, axis=1)\n\nsubgroup_mapping = {name: i for i, name in enumerate(metadata[\"subgroup\"].unique())}\nmetadata[\"group_index\"] = metadata[\"subgroup\"].map(subgroup_mapping)\n\nprint(\"Subgroup Distribution:\")\nprint(metadata[\"subgroup\"].value_counts())\n\n# metadata.to_csv(\"/kaggle/input/waterbird/waterbird/updated_metadata_with_background_subgroups.csv\", index=False)\n\nval_metadata = metadata[metadata[\"split\"] == 1]  # Validation split\ngroup_labels = val_metadata[\"group_index\"].values\nprint(f\"Sample Group Indices (Validation): {group_labels[:10]}\")\n\n# val_indices = val_loader.dataset.indices  \n# group_labels = attributes.loc[val_indices, \"group_index\"].values\n# group_inds = list(group_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:09:11.948144Z","iopub.execute_input":"2025-01-11T00:09:11.948462Z","iopub.status.idle":"2025-01-11T00:09:12.047570Z","shell.execute_reply.started":"2025-01-11T00:09:11.948438Z","shell.execute_reply":"2025-01-11T00:09:12.046743Z"}},"outputs":[{"name":"stdout","text":"Subgroup Distribution:\nsubgroup\nland-background     7051\nwater-background    4737\nName: count, dtype: int64\nSample Group Indices (Validation): [0 1 0 0 1 0 1 1 0 1]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**Calculating Fairness Metrics for Young and Old Groups**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\n\ndef evaluate_group_accuracies(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_preds = {g: [] for g in set(group_labels)}\n    group_truths = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Group Accuracies\")):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_preds[group].append(preds[j])\n                group_truths[group].append(labels.cpu().numpy()[j])\n\n    group_accuracies = {}\n    for group in group_preds:\n        if len(group_preds[group]) == 0:\n            group_accuracies[group] = 0.0\n        else:\n            preds = np.array(group_preds[group])\n            truths = np.array(group_truths[group])\n            group_accuracies[group] = accuracy_score(truths, preds)\n\n    for group, acc in group_accuracies.items():\n        print(f\"Group {group} Accuracy: {acc:.4f}\")\n    \n    return group_accuracies\n\ndef evaluate_demographic_parity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_pprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, _) in enumerate(tqdm(val_loader, desc=\"Evaluating Demographic Parity\")):\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(preds)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                group_pprs[group].append(preds[j])\n\n    ppr_disparities = {}\n    for group in group_pprs:\n        group_positive_rate = np.mean(group_pprs[group])\n        ppr_disparities[group] = group_positive_rate\n\n    for group, ppr in ppr_disparities.items():\n        print(f\"Group {group} PPR: {ppr:.4f}\")\n    \n    return ppr_disparities\n\ndef evaluate_equal_opportunity(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equal Opportunity\")):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                actual_positive = labels[j].cpu().numpy() == 1\n                group_tprs[group].append(tp / (actual_positive + 1e-8))\n\n    tpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n\n    for group, tpr in tpr_disparities.items():\n        print(f\"Group {group} TPR: {tpr:.4f}\")\n    \n    return tpr_disparities\n\ndef evaluate_equalized_odds(model, val_loader, group_labels, device=\"cuda\"):\n    model.eval()\n    group_tprs = {g: [] for g in set(group_labels)}\n    group_fprs = {g: [] for g in set(group_labels)}\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating Equalized Odds\")):\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n\n            batch_start = i * val_loader.batch_size\n            batch_end = batch_start + len(labels)\n            batch_groups = group_labels[batch_start:batch_end]\n\n            for j, group in enumerate(batch_groups):\n                tp = (preds[j] == 1 and labels[j].cpu().numpy() == 1)\n                fp = (preds[j] == 1 and labels[j].cpu().numpy() == 0)\n                actual_positive = labels[j].cpu().numpy() == 1\n                actual_negative = labels[j].cpu().numpy() == 0\n\n                group_tprs[group].append(tp / (actual_positive + 1e-8))\n                group_fprs[group].append(fp / (actual_negative + 1e-8))\n\n    tpr_disparities = {}\n    fpr_disparities = {}\n    for group in group_tprs:\n        tpr_disparities[group] = np.mean(group_tprs[group])\n        fpr_disparities[group] = np.mean(group_fprs[group])\n\n    for group in group_tprs:\n        print(f\"Group {group} TPR: {tpr_disparities[group]:.4f}, FPR: {fpr_disparities[group]:.4f}\")\n    \n    return tpr_disparities, fpr_disparities","metadata":{"execution":{"iopub.execute_input":"2025-01-08T01:04:03.955080Z","iopub.status.busy":"2025-01-08T01:04:03.954771Z","iopub.status.idle":"2025-01-08T01:04:03.971609Z","shell.execute_reply":"2025-01-08T01:04:03.970770Z","shell.execute_reply.started":"2025-01-08T01:04:03.955051Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"wga, group_accuracies = evaluate_worst_group_accuracy(model_before_mitigating, val_loader, group_labels)\ndp_rates = evaluate_demographic_parity(model_before_mitigating, val_loader, group_labels)\neo_tprs = evaluate_equal_opportunity(model_before_mitigating, val_loader, group_labels)\ntpr_disparities, fpr_disparities = evaluate_equalized_odds(model_before_mitigating, val_loader, group_labels)","metadata":{"execution":{"iopub.execute_input":"2025-01-08T01:04:04.516090Z","iopub.status.busy":"2025-01-08T01:04:04.515802Z","iopub.status.idle":"2025-01-08T01:04:12.890898Z","shell.execute_reply":"2025-01-08T01:04:12.889840Z","shell.execute_reply.started":"2025-01-08T01:04:04.516068Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 63/63 [00:02<00:00, 27.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0 Accuracy: 0.4450\n","Group 1 Accuracy: 0.8190\n","Group 2 Accuracy: 0.9452\n","Group 3 Accuracy: 0.7985\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating Demographic Parity: 100%|██████████| 63/63 [00:01<00:00, 31.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0 PPR: 0.5550\n","Group 1 PPR: 0.1810\n","Group 2 PPR: 0.9452\n","Group 3 PPR: 0.7985\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating Equal Opportunity: 100%|██████████| 63/63 [00:02<00:00, 31.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0 TPR: 0.0000\n","Group 1 TPR: 0.0000\n","Group 2 TPR: 0.9452\n","Group 3 TPR: 0.7985\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating Equalized Odds: 100%|██████████| 63/63 [00:02<00:00, 31.23it/s]"]},{"name":"stdout","output_type":"stream","text":["Group 0 TPR: 0.0000, FPR: 0.5550\n","Group 1 TPR: 0.0000, FPR: 0.1810\n","Group 2 TPR: 0.9452, FPR: 0.0000\n","Group 3 TPR: 0.7985, FPR: 0.0000\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":19},{"cell_type":"markdown","source":"# Debiasing with D3M","metadata":{}},{"cell_type":"code","source":"print('YOYO')\nckpts = [model_before_mitigating.state_dict()]\ndda = DDA(model_before_mitigating, ckpts, train_loader, val_loader, group_inds)","metadata":{"execution":{"iopub.execute_input":"2025-01-08T01:04:16.962587Z","iopub.status.busy":"2025-01-08T01:04:16.962189Z","iopub.status.idle":"2025-01-08T01:06:06.055203Z","shell.execute_reply":"2025-01-08T01:06:06.054223Z","shell.execute_reply.started":"2025-01-08T01:04:16.962559Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["YOYO\n"]},{"name":"stderr","output_type":"stream","text":["Finalizing features for all model IDs..: 100%|██████████| 1/1 [00:00<00:00, 4405.78it/s]\n","Finalizing scores for all model IDs..: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n"]}],"execution_count":20},{"cell_type":"code","source":"# debiased_inds = dda.debias(use_heuristic=False, num_to_discard=100)\ndebiased_inds = dda.debias(use_heuristic=True)\nlen(debiased_inds)","metadata":{"execution":{"iopub.execute_input":"2025-01-08T01:06:20.995008Z","iopub.status.busy":"2025-01-08T01:06:20.994689Z","iopub.status.idle":"2025-01-08T01:06:23.636328Z","shell.execute_reply":"2025-01-08T01:06:23.635376Z","shell.execute_reply.started":"2025-01-08T01:06:20.994986Z"},"trusted":true},"outputs":[{"data":{"text/plain":["16275"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"execution_count":22},{"cell_type":"code","source":"import copy\n\ndeep_copy_model = copy.deepcopy(model_before_mitigating)","metadata":{"execution":{"iopub.execute_input":"2025-01-08T00:16:46.369086Z","iopub.status.busy":"2025-01-08T00:16:46.368521Z","iopub.status.idle":"2025-01-08T00:16:46.400823Z","shell.execute_reply":"2025-01-08T00:16:46.399947Z","shell.execute_reply.started":"2025-01-08T00:16:46.369023Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Machine Unlearning","metadata":{}},{"cell_type":"code","source":"harmful_indices = debiased_inds","metadata":{"execution":{"iopub.execute_input":"2025-01-08T00:17:12.505727Z","iopub.status.busy":"2025-01-08T00:17:12.505393Z","iopub.status.idle":"2025-01-08T00:17:12.509819Z","shell.execute_reply":"2025-01-08T00:17:12.508709Z","shell.execute_reply.started":"2025-01-08T00:17:12.505696Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def remove_influence(model, dataloader, harmful_indices, factor, device=\"cuda\"):\n    model.eval()\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    for inputs, labels in harmful_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(model.parameters(), grads):\n                param -= grad * factor\n\n    return model\n\nresults ={'factor':[], 'model':[], 'min':[], 'max':[], 'gap':[]}\nfactors = np.linspace(0.00001, 0.0001, 2)\n\nfor factor in factors:\n    newdeepmodel = copy.deepcopy(deep_copy_model)\n    m = remove_influence(newdeepmodel, train_loader, harmful_indices, factor, device=\"cuda\")\n    wga, group_accs = evaluate_worst_group_accuracy(m, val_loader, group_inds, device=\"cuda\")\n    current_gap = (max(group_accs.values()) - wga)\n    results['model'].append(m)\n    results['min'].append(wga)\n    results['max'].append(max(group_accs.values()))\n    results['gap'].append(current_gap)\n    results['factor'].append(factor)","metadata":{"execution":{"iopub.execute_input":"2025-01-07T19:21:35.483585Z","iopub.status.busy":"2025-01-07T19:21:35.483278Z","iopub.status.idle":"2025-01-07T19:38:07.986398Z","shell.execute_reply":"2025-01-07T19:38:07.985362Z","shell.execute_reply.started":"2025-01-07T19:21:35.483560Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 312/312 [00:10<00:00, 30.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Group 0 Accuracy: 0.9080\n","Group 1 Accuracy: 0.9838\n","Group 2 Accuracy: 0.7408\n","Group 3 Accuracy: 0.3734\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating WGA: 100%|██████████| 312/312 [00:09<00:00, 31.40it/s]"]},{"name":"stdout","output_type":"stream","text":["Group 0 Accuracy: 0.9466\n","Group 1 Accuracy: 0.9877\n","Group 2 Accuracy: 0.6921\n","Group 3 Accuracy: 0.3690\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":35},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(results).sort_values('factor')\ndf","metadata":{"execution":{"iopub.execute_input":"2025-01-07T19:40:09.687904Z","iopub.status.busy":"2025-01-07T19:40:09.687564Z","iopub.status.idle":"2025-01-07T19:40:09.702851Z","shell.execute_reply":"2025-01-07T19:40:09.702144Z","shell.execute_reply.started":"2025-01-07T19:40:09.687877Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>factor</th>\n","      <th>model</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>gap</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00001</td>\n","      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n","      <td>0.373377</td>\n","      <td>0.983794</td>\n","      <td>0.610417</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.00010</td>\n","      <td>ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...</td>\n","      <td>0.369048</td>\n","      <td>0.987742</td>\n","      <td>0.618694</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    factor                                              model       min  \\\n","0  0.00001  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.373377   \n","1  0.00010  ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=...  0.369048   \n","\n","        max       gap  \n","0  0.983794  0.610417  \n","1  0.987742  0.618694  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"execution_count":36},{"cell_type":"markdown","source":"Now, it's time to investigate what are the best approaches to machine unlearning and how can we formulate that.","metadata":{}},{"cell_type":"markdown","source":"What are the other approaches to machine unlearning?","metadata":{}},{"cell_type":"markdown","source":"# Fair Pruning","metadata":{}},{"cell_type":"code","source":"import torch\nimport copy\n\ndef fair_pruning(model, dataloader, harmful_indices, threshold=0.01, device=\"cuda\"):\n    model.eval()\n    pruned_model = copy.deepcopy(model)\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    parameter_gradients = []\n    for inputs, labels in tqdm(harmful_loader, desc=\"Calculating Gradients\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = pruned_model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, pruned_model.parameters(), retain_graph=True)\n        parameter_gradients.append([grad.clone() for grad in grads])\n\n    with torch.no_grad():\n        for param, grads in zip(pruned_model.parameters(), zip(*parameter_gradients)):\n            mean_grad = torch.mean(torch.stack(grads), dim=0)\n            param[torch.abs(mean_grad) < threshold] = 0.0\n\n    return pruned_model\n\npruned_model = fair_pruning(model_before_mitigating, train_loader, harmful_indices, threshold=0.01)\n\nwga, group_accs = evaluate_worst_group_accuracy(pruned_model, val_loader, group_inds, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Differentially Private Influence Functions for Unlearning","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport copy\n\ndef dp_influence_unlearning(model, dataloader, harmful_indices, epsilon=1.0, delta=1e-5, device=\"cuda\"):\n    model.eval()\n    updated_model = copy.deepcopy(model)\n    harmful_dataset = torch.utils.data.Subset(dataloader.dataset, harmful_indices)\n    harmful_loader = torch.utils.data.DataLoader(harmful_dataset, batch_size=1)\n\n    sensitivity = 1.0 / len(harmful_loader)\n    noise_scale = sensitivity * np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n\n    for inputs, labels in tqdm(harmful_loader, desc=\"Applying DP Influence Unlearning\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = updated_model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        grads = torch.autograd.grad(loss, updated_model.parameters(), retain_graph=True)\n\n        with torch.no_grad():\n            for param, grad in zip(updated_model.parameters(), grads):\n                noise = torch.normal(mean=0, std=noise_scale, size=grad.shape, device=device)\n                param -= (grad + noise)\n\n    return updated_model\n\ndp_model = dp_influence_unlearning(model_before_mitigating, train_loader, harmful_indices, epsilon=1.0, delta=1e-5)\nwga, group_accs = evaluate_worst_group_accuracy(dp_model, val_loader, group_inds, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}